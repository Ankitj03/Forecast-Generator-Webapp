{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'rpy2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-127ec7552152>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlayouts\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprophet_forecast\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0marima_forecast\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miterateclean\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mets_forecast\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmin_mape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mflask\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFlask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mflask\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/generator and webpage/website/layouts.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcleandata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mts_clean\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseason_clean\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpmdarima\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marima\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/generator and webpage/website/cleandata.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mrpy2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrobjects\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpackages\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimportr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;31m#get ts object as python object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mrpy2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrobjects\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas2ri\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'rpy2'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import calendar\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "from layouts import prophet_forecast,arima_forecast,iterateclean,ets_forecast,min_mape\n",
    "from flask import Flask\n",
    "from flask import request\n",
    "from flask import render_template\n",
    "from flask import send_file\n",
    "from werkzeug import secure_filename\n",
    "from flask import flash,redirect,url_for,abort\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "from mysql.connector import Error\n",
    "try:\n",
    "    conn = mysql.connector.connect(host='127.0.0.1',\n",
    "                                       port='3306',\n",
    "                                       database='db',\n",
    "                                       user='ankit',\n",
    "                                       password='ankit123')\n",
    "    if conn.is_connected():\n",
    "        print('Connected to MySQL database')\n",
    "    else:\n",
    "        print(\"nope\")\n",
    "except Error as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = Flask(__name__, template_folder = 'template')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: Do not use the development server in a production environment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug: * Running on http://127.0.0.1:9000/ (Press CTRL+C to quit)\n",
      "INFO:werkzeug:127.0.0.1 - - [15/Aug/2019 11:02:58] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv\n",
      "bestfit\n",
      "size\n",
      "2015-01-01\n",
      "2019-07-01\n",
      "6\n",
      "InputFile.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ankit.joshi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:5096: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n",
      "INFO:fbprophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
      "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      "C:\\Users\\ankit.joshi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pystan\\misc.py:399: FutureWarning:\n",
      "\n",
      "Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "\n",
      "INFO:fbprophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
      "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      "C:\\Users\\ankit.joshi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pystan\\misc.py:399: FutureWarning:\n",
      "\n",
      "Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit ARIMA: order=(0, 1, 0) seasonal_order=(0, 1, 1, 12); AIC=nan, BIC=nan, Fit time=nan seconds\n",
      "Fit ARIMA: order=(0, 1, 0) seasonal_order=(0, 1, 0, 12); AIC=339.339, BIC=341.428, Fit time=0.008 seconds\n",
      "Fit ARIMA: order=(1, 1, 0) seasonal_order=(1, 1, 0, 12); AIC=326.443, BIC=330.621, Fit time=0.433 seconds\n",
      "Fit ARIMA: order=(0, 1, 1) seasonal_order=(0, 1, 1, 12); AIC=nan, BIC=nan, Fit time=nan seconds\n",
      "Fit ARIMA: order=(1, 1, 0) seasonal_order=(0, 1, 0, 12); AIC=333.940, BIC=337.073, Fit time=0.046 seconds\n",
      "Fit ARIMA: order=(1, 1, 0) seasonal_order=(2, 1, 0, 12); AIC=nan, BIC=nan, Fit time=nan seconds\n",
      "Fit ARIMA: order=(1, 1, 0) seasonal_order=(1, 1, 1, 12); AIC=nan, BIC=nan, Fit time=nan seconds\n",
      "Fit ARIMA: order=(1, 1, 0) seasonal_order=(2, 1, 1, 12); AIC=nan, BIC=nan, Fit time=nan seconds\n",
      "Fit ARIMA: order=(0, 1, 0) seasonal_order=(1, 1, 0, 12); AIC=334.906, BIC=338.039, Fit time=0.223 seconds\n",
      "Fit ARIMA: order=(2, 1, 0) seasonal_order=(1, 1, 0, 12); AIC=314.254, BIC=319.477, Fit time=0.368 seconds\n",
      "Fit ARIMA: order=(2, 1, 1) seasonal_order=(1, 1, 0, 12); AIC=310.558, BIC=316.825, Fit time=0.405 seconds\n",
      "Fit ARIMA: order=(3, 1, 2) seasonal_order=(1, 1, 0, 12); AIC=314.231, BIC=322.587, Fit time=0.645 seconds\n",
      "Fit ARIMA: order=(2, 1, 1) seasonal_order=(0, 1, 0, 12); AIC=313.973, BIC=319.196, Fit time=0.270 seconds\n",
      "Fit ARIMA: order=(2, 1, 1) seasonal_order=(2, 1, 0, 12); AIC=nan, BIC=nan, Fit time=nan seconds\n",
      "Fit ARIMA: order=(2, 1, 1) seasonal_order=(1, 1, 1, 12); AIC=nan, BIC=nan, Fit time=nan seconds\n",
      "Fit ARIMA: order=(2, 1, 1) seasonal_order=(2, 1, 1, 12); AIC=nan, BIC=nan, Fit time=nan seconds\n",
      "Fit ARIMA: order=(1, 1, 1) seasonal_order=(1, 1, 0, 12); AIC=313.780, BIC=319.003, Fit time=0.338 seconds\n",
      "Fit ARIMA: order=(3, 1, 1) seasonal_order=(1, 1, 0, 12); AIC=312.504, BIC=319.815, Fit time=0.373 seconds\n",
      "Fit ARIMA: order=(2, 1, 2) seasonal_order=(1, 1, 0, 12); AIC=312.434, BIC=319.745, Fit time=0.474 seconds\n",
      "Total fit time: 3.614 seconds\n",
      "Fit ARIMA: order=(0, 1, 0) seasonal_order=(0, 1, 1, 12); AIC=nan, BIC=nan, Fit time=nan seconds\n",
      "Fit ARIMA: order=(0, 1, 0) seasonal_order=(0, 1, 0, 12); AIC=474.444, BIC=477.247, Fit time=0.012 seconds\n",
      "Fit ARIMA: order=(1, 1, 0) seasonal_order=(1, 1, 0, 12); AIC=461.352, BIC=466.957, Fit time=0.290 seconds\n",
      "Fit ARIMA: order=(0, 1, 1) seasonal_order=(0, 1, 1, 12); AIC=nan, BIC=nan, Fit time=nan seconds\n",
      "Fit ARIMA: order=(1, 1, 0) seasonal_order=(0, 1, 0, 12); AIC=465.793, BIC=469.997, Fit time=0.029 seconds\n",
      "Fit ARIMA: order=(1, 1, 0) seasonal_order=(2, 1, 0, 12); AIC=463.128, BIC=470.134, Fit time=0.697 seconds\n",
      "Fit ARIMA: order=(1, 1, 0) seasonal_order=(1, 1, 1, 12); AIC=nan, BIC=nan, Fit time=nan seconds\n",
      "Fit ARIMA: order=(1, 1, 0) seasonal_order=(2, 1, 1, 12); AIC=nan, BIC=nan, Fit time=nan seconds\n",
      "Fit ARIMA: order=(0, 1, 0) seasonal_order=(1, 1, 0, 12); AIC=471.734, BIC=475.938, Fit time=0.127 seconds\n",
      "Fit ARIMA: order=(2, 1, 0) seasonal_order=(1, 1, 0, 12); AIC=447.427, BIC=454.433, Fit time=0.109 seconds\n",
      "Fit ARIMA: order=(2, 1, 1) seasonal_order=(1, 1, 0, 12); AIC=442.511, BIC=450.918, Fit time=0.607 seconds\n",
      "Fit ARIMA: order=(3, 1, 2) seasonal_order=(1, 1, 0, 12); AIC=445.729, BIC=456.939, Fit time=0.795 seconds\n",
      "Fit ARIMA: order=(2, 1, 1) seasonal_order=(0, 1, 0, 12); AIC=444.188, BIC=451.194, Fit time=0.233 seconds\n",
      "Fit ARIMA: order=(2, 1, 1) seasonal_order=(2, 1, 0, 12); AIC=444.509, BIC=454.317, Fit time=1.783 seconds\n",
      "Fit ARIMA: order=(2, 1, 1) seasonal_order=(1, 1, 1, 12); AIC=nan, BIC=nan, Fit time=nan seconds\n",
      "Fit ARIMA: order=(2, 1, 1) seasonal_order=(2, 1, 1, 12); AIC=nan, BIC=nan, Fit time=nan seconds\n",
      "Fit ARIMA: order=(1, 1, 1) seasonal_order=(1, 1, 0, 12); AIC=444.111, BIC=451.117, Fit time=0.520 seconds\n",
      "Fit ARIMA: order=(3, 1, 1) seasonal_order=(1, 1, 0, 12); AIC=444.114, BIC=453.922, Fit time=0.820 seconds\n",
      "Fit ARIMA: order=(2, 1, 2) seasonal_order=(1, 1, 0, 12); AIC=443.759, BIC=453.568, Fit time=0.664 seconds\n",
      "Total fit time: 6.708 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ankit.joshi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:165: ValueWarning:\n",
      "\n",
      "No frequency information was provided, so inferred frequency MS will be used.\n",
      "\n",
      "C:\\Users\\ankit.joshi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\holtwinters.py:712: ConvergenceWarning:\n",
      "\n",
      "Optimization failed to converge. Check mle_retvals.\n",
      "\n",
      "C:\\Users\\ankit.joshi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:165: ValueWarning:\n",
      "\n",
      "No frequency information was provided, so inferred frequency MS will be used.\n",
      "\n",
      "C:\\Users\\ankit.joshi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\holtwinters.py:712: ConvergenceWarning:\n",
      "\n",
      "Optimization failed to converge. Check mle_retvals.\n",
      "\n",
      "C:\\Users\\ankit.joshi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:5096: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0L\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fbprophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
      "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      "C:\\Users\\ankit.joshi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pystan\\misc.py:399: FutureWarning:\n",
      "\n",
      "Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "\n",
      "INFO:fbprophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
      "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      "C:\\Users\\ankit.joshi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pystan\\misc.py:399: FutureWarning:\n",
      "\n",
      "Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit ARIMA: order=(0, 1, 0) seasonal_order=(0, 1, 1, 12); AIC=nan, BIC=nan, Fit time=nan seconds\n",
      "Fit ARIMA: order=(0, 1, 0) seasonal_order=(0, 1, 0, 12); AIC=461.837, BIC=463.926, Fit time=0.011 seconds\n",
      "Fit ARIMA: order=(1, 1, 0) seasonal_order=(1, 1, 0, 12); AIC=458.468, BIC=462.647, Fit time=0.074 seconds\n",
      "Fit ARIMA: order=(0, 1, 1) seasonal_order=(0, 1, 1, 12); AIC=nan, BIC=nan, Fit time=nan seconds\n",
      "Fit ARIMA: order=(1, 1, 0) seasonal_order=(0, 1, 0, 12); AIC=461.187, BIC=464.321, Fit time=0.025 seconds\n",
      "Fit ARIMA: order=(1, 1, 0) seasonal_order=(2, 1, 0, 12); AIC=nan, BIC=nan, Fit time=nan seconds\n",
      "Fit ARIMA: order=(1, 1, 0) seasonal_order=(1, 1, 1, 12); AIC=nan, BIC=nan, Fit time=nan seconds\n",
      "Fit ARIMA: order=(1, 1, 0) seasonal_order=(2, 1, 1, 12); AIC=nan, BIC=nan, Fit time=nan seconds\n",
      "Fit ARIMA: order=(0, 1, 0) seasonal_order=(1, 1, 0, 12); AIC=459.461, BIC=462.594, Fit time=0.104 seconds\n",
      "Fit ARIMA: order=(2, 1, 0) seasonal_order=(1, 1, 0, 12); AIC=461.068, BIC=466.291, Fit time=0.126 seconds\n",
      "Fit ARIMA: order=(1, 1, 1) seasonal_order=(1, 1, 0, 12); AIC=457.947, BIC=463.169, Fit time=0.330 seconds\n",
      "Fit ARIMA: order=(2, 1, 2) seasonal_order=(1, 1, 0, 12); AIC=461.077, BIC=468.389, Fit time=0.625 seconds\n",
      "Fit ARIMA: order=(1, 1, 1) seasonal_order=(0, 1, 0, 12); AIC=460.286, BIC=464.464, Fit time=0.128 seconds\n",
      "Fit ARIMA: order=(1, 1, 1) seasonal_order=(2, 1, 0, 12); AIC=nan, BIC=nan, Fit time=nan seconds\n",
      "Fit ARIMA: order=(1, 1, 1) seasonal_order=(1, 1, 1, 12); AIC=nan, BIC=nan, Fit time=nan seconds\n",
      "Fit ARIMA: order=(1, 1, 1) seasonal_order=(2, 1, 1, 12); AIC=nan, BIC=nan, Fit time=nan seconds\n",
      "Fit ARIMA: order=(0, 1, 1) seasonal_order=(1, 1, 0, 12); AIC=459.525, BIC=463.703, Fit time=0.067 seconds\n",
      "Fit ARIMA: order=(2, 1, 1) seasonal_order=(1, 1, 0, 12); AIC=459.488, BIC=465.755, Fit time=0.387 seconds\n",
      "Fit ARIMA: order=(1, 1, 2) seasonal_order=(1, 1, 0, 12); AIC=458.629, BIC=464.896, Fit time=0.271 seconds\n",
      "Total fit time: 2.171 seconds\n",
      "Fit ARIMA: order=(0, 1, 0) seasonal_order=(0, 1, 1, 12); AIC=nan, BIC=nan, Fit time=nan seconds\n",
      "Fit ARIMA: order=(0, 1, 0) seasonal_order=(0, 1, 0, 12); AIC=661.532, BIC=664.335, Fit time=0.009 seconds\n",
      "Fit ARIMA: order=(1, 1, 0) seasonal_order=(1, 1, 0, 12); AIC=658.312, BIC=663.917, Fit time=0.066 seconds\n",
      "Fit ARIMA: order=(0, 1, 1) seasonal_order=(0, 1, 1, 12); AIC=nan, BIC=nan, Fit time=nan seconds\n",
      "Fit ARIMA: order=(1, 1, 0) seasonal_order=(0, 1, 0, 12); AIC=661.927, BIC=666.131, Fit time=0.026 seconds\n",
      "Fit ARIMA: order=(1, 1, 0) seasonal_order=(2, 1, 0, 12); AIC=660.101, BIC=667.107, Fit time=0.220 seconds\n",
      "Fit ARIMA: order=(1, 1, 0) seasonal_order=(1, 1, 1, 12); AIC=nan, BIC=nan, Fit time=nan seconds\n",
      "Fit ARIMA: order=(1, 1, 0) seasonal_order=(2, 1, 1, 12); AIC=nan, BIC=nan, Fit time=nan seconds\n",
      "Fit ARIMA: order=(0, 1, 0) seasonal_order=(1, 1, 0, 12); AIC=658.278, BIC=662.482, Fit time=0.047 seconds\n",
      "Fit ARIMA: order=(0, 1, 1) seasonal_order=(1, 1, 0, 12); AIC=658.493, BIC=664.098, Fit time=0.070 seconds\n",
      "Fit ARIMA: order=(1, 1, 1) seasonal_order=(1, 1, 0, 12); AIC=656.308, BIC=663.314, Fit time=0.241 seconds\n",
      "Fit ARIMA: order=(1, 1, 1) seasonal_order=(0, 1, 0, 12); AIC=659.630, BIC=665.235, Fit time=0.126 seconds\n",
      "Fit ARIMA: order=(1, 1, 1) seasonal_order=(2, 1, 0, 12); AIC=658.112, BIC=666.520, Fit time=0.458 seconds\n",
      "Fit ARIMA: order=(1, 1, 1) seasonal_order=(1, 1, 1, 12); AIC=nan, BIC=nan, Fit time=nan seconds\n",
      "Fit ARIMA: order=(1, 1, 1) seasonal_order=(2, 1, 1, 12); AIC=nan, BIC=nan, Fit time=nan seconds\n",
      "Fit ARIMA: order=(2, 1, 1) seasonal_order=(1, 1, 0, 12); AIC=657.548, BIC=665.955, Fit time=0.315 seconds\n",
      "Fit ARIMA: order=(1, 1, 2) seasonal_order=(1, 1, 0, 12); AIC=657.606, BIC=666.013, Fit time=0.306 seconds\n",
      "Fit ARIMA: order=(2, 1, 2) seasonal_order=(1, 1, 0, 12); AIC=656.555, BIC=666.363, Fit time=0.633 seconds\n",
      "Total fit time: 2.536 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ankit.joshi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:165: ValueWarning:\n",
      "\n",
      "No frequency information was provided, so inferred frequency MS will be used.\n",
      "\n",
      "C:\\Users\\ankit.joshi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\holtwinters.py:712: ConvergenceWarning:\n",
      "\n",
      "Optimization failed to converge. Check mle_retvals.\n",
      "\n",
      "C:\\Users\\ankit.joshi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:165: ValueWarning:\n",
      "\n",
      "No frequency information was provided, so inferred frequency MS will be used.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5L\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ankit.joshi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:5096: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n",
      "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
      "INFO:fbprophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
      "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      "INFO:fbprophet:n_changepoints greater than number of observations.Using 18.\n",
      "C:\\Users\\ankit.joshi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pystan\\misc.py:399: FutureWarning:\n",
      "\n",
      "Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "\n",
      "INFO:fbprophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
      "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      "INFO:fbprophet:n_changepoints greater than number of observations.Using 23.\n",
      "C:\\Users\\ankit.joshi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pystan\\misc.py:399: FutureWarning:\n",
      "\n",
      "Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit ARIMA: order=(0, 1, 0) seasonal_order=(0, 1, 1, 12); AIC=nan, BIC=nan, Fit time=nan seconds\n",
      "Fit ARIMA: order=(0, 1, 0) seasonal_order=(0, 1, 0, 12); AIC=183.520, BIC=184.316, Fit time=0.010 seconds\n",
      "Fit ARIMA: order=(1, 1, 0) seasonal_order=(1, 1, 0, 12); AIC=nan, BIC=nan, Fit time=nan seconds\n",
      "Fit ARIMA: order=(0, 1, 1) seasonal_order=(0, 1, 1, 12); AIC=nan, BIC=nan, Fit time=nan seconds\n",
      "Fit ARIMA: order=(0, 1, 0) seasonal_order=(1, 1, 0, 12); AIC=nan, BIC=nan, Fit time=nan seconds\n",
      "Fit ARIMA: order=(0, 1, 0) seasonal_order=(1, 1, 1, 12); AIC=nan, BIC=nan, Fit time=nan seconds\n",
      "Fit ARIMA: order=(1, 1, 0) seasonal_order=(0, 1, 0, 12); AIC=184.758, BIC=185.951, Fit time=0.080 seconds\n",
      "Fit ARIMA: order=(0, 1, 1) seasonal_order=(0, 1, 0, 12); AIC=184.423, BIC=185.617, Fit time=0.110 seconds\n",
      "Fit ARIMA: order=(1, 1, 1) seasonal_order=(0, 1, 0, 12); AIC=186.361, BIC=187.952, Fit time=0.194 seconds\n",
      "Total fit time: 0.409 seconds\n",
      "Fit ARIMA: order=(0, 1, 0) seasonal_order=(0, 1, 1, 12); AIC=nan, BIC=nan, Fit time=nan seconds\n",
      "Fit ARIMA: order=(0, 1, 0) seasonal_order=(0, 1, 0, 12); AIC=310.950, BIC=312.731, Fit time=0.013 seconds\n",
      "Fit ARIMA: order=(1, 1, 0) seasonal_order=(1, 1, 0, 12); AIC=309.109, BIC=312.671, Fit time=0.071 seconds\n",
      "Fit ARIMA: order=(0, 1, 1) seasonal_order=(0, 1, 1, 12); AIC=nan, BIC=nan, Fit time=nan seconds\n",
      "Fit ARIMA: order=(1, 1, 0) seasonal_order=(0, 1, 0, 12); AIC=313.417, BIC=316.088, Fit time=0.032 seconds\n",
      "Fit ARIMA: order=(1, 1, 0) seasonal_order=(2, 1, 0, 12); AIC=nan, BIC=nan, Fit time=nan seconds\n",
      "Fit ARIMA: order=(1, 1, 0) seasonal_order=(1, 1, 1, 12); AIC=nan, BIC=nan, Fit time=nan seconds\n",
      "Fit ARIMA: order=(1, 1, 0) seasonal_order=(2, 1, 1, 12); AIC=nan, BIC=nan, Fit time=nan seconds\n",
      "Fit ARIMA: order=(0, 1, 0) seasonal_order=(1, 1, 0, 12); AIC=306.736, BIC=309.407, Fit time=0.257 seconds\n",
      "Fit ARIMA: order=(0, 1, 1) seasonal_order=(1, 1, 0, 12); AIC=308.740, BIC=312.302, Fit time=0.307 seconds\n",
      "Fit ARIMA: order=(1, 1, 1) seasonal_order=(1, 1, 0, 12); AIC=307.484, BIC=311.936, Fit time=0.631 seconds\n",
      "Fit ARIMA: order=(0, 1, 0) seasonal_order=(2, 1, 0, 12); AIC=nan, BIC=nan, Fit time=nan seconds\n",
      "Fit ARIMA: order=(0, 1, 0) seasonal_order=(1, 1, 1, 12); AIC=nan, BIC=nan, Fit time=nan seconds\n",
      "Fit ARIMA: order=(0, 1, 0) seasonal_order=(2, 1, 1, 12); AIC=nan, BIC=nan, Fit time=nan seconds\n",
      "Total fit time: 1.334 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ankit.joshi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:165: ValueWarning:\n",
      "\n",
      "No frequency information was provided, so inferred frequency MS will be used.\n",
      "\n",
      "C:\\Users\\ankit.joshi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\holtwinters.py:712: ConvergenceWarning:\n",
      "\n",
      "Optimization failed to converge. Check mle_retvals.\n",
      "\n",
      "C:\\Users\\ankit.joshi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:165: ValueWarning:\n",
      "\n",
      "No frequency information was provided, so inferred frequency MS will be used.\n",
      "\n",
      "C:\\Users\\ankit.joshi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\holtwinters.py:712: ConvergenceWarning:\n",
      "\n",
      "Optimization failed to converge. Check mle_retvals.\n",
      "\n",
      "C:\\Users\\ankit.joshi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:754: FutureWarning:\n",
      "\n",
      "Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "\n",
      "C:\\Users\\ankit.joshi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:5096: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n",
      "INFO:fbprophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187ML\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      "C:\\Users\\ankit.joshi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pystan\\misc.py:399: FutureWarning:\n",
      "\n",
      "Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "\n",
      "INFO:fbprophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
      "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      "C:\\Users\\ankit.joshi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pystan\\misc.py:399: FutureWarning:\n",
      "\n",
      "Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit ARIMA: order=(0, 1, 0) seasonal_order=(0, 1, 1, 12); AIC=nan, BIC=nan, Fit time=nan seconds\n",
      "Fit ARIMA: order=(0, 1, 0) seasonal_order=(0, 1, 0, 12); AIC=246.594, BIC=248.683, Fit time=0.008 seconds\n",
      "Fit ARIMA: order=(1, 1, 0) seasonal_order=(1, 1, 0, 12); AIC=243.502, BIC=247.680, Fit time=0.140 seconds\n",
      "Fit ARIMA: order=(0, 1, 1) seasonal_order=(0, 1, 1, 12); AIC=nan, BIC=nan, Fit time=nan seconds\n",
      "Fit ARIMA: order=(1, 1, 0) seasonal_order=(0, 1, 0, 12); AIC=244.321, BIC=247.454, Fit time=0.078 seconds\n",
      "Fit ARIMA: order=(1, 1, 0) seasonal_order=(2, 1, 0, 12); AIC=nan, BIC=nan, Fit time=nan seconds\n",
      "Fit ARIMA: order=(1, 1, 0) seasonal_order=(1, 1, 1, 12); AIC=nan, BIC=nan, Fit time=nan seconds\n",
      "Fit ARIMA: order=(1, 1, 0) seasonal_order=(2, 1, 1, 12); AIC=nan, BIC=nan, Fit time=nan seconds\n",
      "Fit ARIMA: order=(0, 1, 0) seasonal_order=(1, 1, 0, 12); AIC=246.179, BIC=249.313, Fit time=0.091 seconds\n",
      "Fit ARIMA: order=(2, 1, 0) seasonal_order=(1, 1, 0, 12); AIC=245.501, BIC=250.724, Fit time=0.222 seconds\n",
      "Fit ARIMA: order=(1, 1, 1) seasonal_order=(1, 1, 0, 12); AIC=240.927, BIC=246.150, Fit time=0.298 seconds\n",
      "Fit ARIMA: order=(2, 1, 2) seasonal_order=(1, 1, 0, 12); AIC=244.924, BIC=252.236, Fit time=0.305 seconds\n",
      "Fit ARIMA: order=(1, 1, 1) seasonal_order=(0, 1, 0, 12); AIC=246.124, BIC=250.302, Fit time=0.144 seconds\n",
      "Fit ARIMA: order=(1, 1, 1) seasonal_order=(2, 1, 0, 12); AIC=nan, BIC=nan, Fit time=nan seconds\n",
      "Fit ARIMA: order=(1, 1, 1) seasonal_order=(1, 1, 1, 12); AIC=nan, BIC=nan, Fit time=nan seconds\n",
      "Fit ARIMA: order=(1, 1, 1) seasonal_order=(2, 1, 1, 12); AIC=nan, BIC=nan, Fit time=nan seconds\n",
      "Fit ARIMA: order=(0, 1, 1) seasonal_order=(1, 1, 0, 12); AIC=238.977, BIC=243.155, Fit time=0.227 seconds\n",
      "Fit ARIMA: order=(0, 1, 2) seasonal_order=(1, 1, 0, 12); AIC=240.932, BIC=246.154, Fit time=0.393 seconds\n",
      "Fit ARIMA: order=(1, 1, 2) seasonal_order=(1, 1, 0, 12); AIC=242.837, BIC=249.104, Fit time=0.450 seconds\n",
      "Fit ARIMA: order=(0, 1, 1) seasonal_order=(0, 1, 0, 12); AIC=240.247, BIC=243.381, Fit time=0.088 seconds\n",
      "Fit ARIMA: order=(0, 1, 1) seasonal_order=(2, 1, 0, 12); AIC=nan, BIC=nan, Fit time=nan seconds\n",
      "Fit ARIMA: order=(0, 1, 1) seasonal_order=(1, 1, 1, 12); AIC=nan, BIC=nan, Fit time=nan seconds\n",
      "Fit ARIMA: order=(0, 1, 1) seasonal_order=(2, 1, 1, 12); AIC=nan, BIC=nan, Fit time=nan seconds\n",
      "Total fit time: 2.476 seconds\n",
      "Fit ARIMA: order=(0, 1, 0) seasonal_order=(0, 1, 1, 12); AIC=nan, BIC=nan, Fit time=nan seconds\n",
      "Fit ARIMA: order=(0, 1, 0) seasonal_order=(0, 1, 0, 12); AIC=359.758, BIC=362.560, Fit time=0.012 seconds\n",
      "Fit ARIMA: order=(1, 1, 0) seasonal_order=(1, 1, 0, 12); AIC=352.266, BIC=357.871, Fit time=0.220 seconds\n",
      "Fit ARIMA: order=(0, 1, 1) seasonal_order=(0, 1, 1, 12); AIC=nan, BIC=nan, Fit time=nan seconds\n",
      "Fit ARIMA: order=(1, 1, 0) seasonal_order=(0, 1, 0, 12); AIC=355.824, BIC=360.027, Fit time=0.066 seconds\n",
      "Fit ARIMA: order=(1, 1, 0) seasonal_order=(2, 1, 0, 12); AIC=354.077, BIC=361.083, Fit time=0.512 seconds\n",
      "Fit ARIMA: order=(1, 1, 0) seasonal_order=(1, 1, 1, 12); AIC=nan, BIC=nan, Fit time=nan seconds\n",
      "Fit ARIMA: order=(1, 1, 0) seasonal_order=(2, 1, 1, 12); AIC=nan, BIC=nan, Fit time=nan seconds\n",
      "Fit ARIMA: order=(0, 1, 0) seasonal_order=(1, 1, 0, 12); AIC=360.071, BIC=364.275, Fit time=0.096 seconds\n",
      "Fit ARIMA: order=(2, 1, 0) seasonal_order=(1, 1, 0, 12); AIC=354.132, BIC=361.138, Fit time=0.240 seconds\n",
      "Fit ARIMA: order=(1, 1, 1) seasonal_order=(1, 1, 0, 12); AIC=354.036, BIC=361.042, Fit time=0.267 seconds\n",
      "Fit ARIMA: order=(2, 1, 1) seasonal_order=(1, 1, 0, 12); AIC=353.784, BIC=362.192, Fit time=0.553 seconds\n",
      "Total fit time: 1.977 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ankit.joshi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:165: ValueWarning:\n",
      "\n",
      "No frequency information was provided, so inferred frequency MS will be used.\n",
      "\n",
      "C:\\Users\\ankit.joshi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:165: ValueWarning:\n",
      "\n",
      "No frequency information was provided, so inferred frequency MS will be used.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.5L\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ankit.joshi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:5096: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n",
      "INFO:fbprophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
      "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      "C:\\Users\\ankit.joshi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pystan\\misc.py:399: FutureWarning:\n",
      "\n",
      "Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "\n",
      "INFO:fbprophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
      "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      "C:\\Users\\ankit.joshi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pystan\\misc.py:399: FutureWarning:\n",
      "\n",
      "Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit ARIMA: order=(0, 1, 0) seasonal_order=(0, 1, 1, 12); AIC=nan, BIC=nan, Fit time=nan seconds\n",
      "Fit ARIMA: order=(0, 1, 0) seasonal_order=(0, 1, 0, 12); AIC=470.163, BIC=472.252, Fit time=0.010 seconds\n",
      "Fit ARIMA: order=(1, 1, 0) seasonal_order=(1, 1, 0, 12); AIC=463.771, BIC=467.949, Fit time=0.070 seconds\n",
      "Fit ARIMA: order=(0, 1, 1) seasonal_order=(0, 1, 1, 12); AIC=nan, BIC=nan, Fit time=nan seconds\n",
      "Fit ARIMA: order=(1, 1, 0) seasonal_order=(0, 1, 0, 12); AIC=463.209, BIC=466.343, Fit time=0.016 seconds\n",
      "Fit ARIMA: order=(1, 1, 0) seasonal_order=(0, 1, 1, 12); AIC=nan, BIC=nan, Fit time=nan seconds\n",
      "Fit ARIMA: order=(1, 1, 0) seasonal_order=(1, 1, 1, 12); AIC=nan, BIC=nan, Fit time=nan seconds\n",
      "Fit ARIMA: order=(2, 1, 0) seasonal_order=(0, 1, 0, 12); AIC=463.544, BIC=467.722, Fit time=0.024 seconds\n",
      "Fit ARIMA: order=(1, 1, 1) seasonal_order=(0, 1, 0, 12); AIC=459.819, BIC=463.997, Fit time=0.158 seconds\n",
      "Fit ARIMA: order=(2, 1, 2) seasonal_order=(0, 1, 0, 12); AIC=463.642, BIC=469.909, Fit time=0.388 seconds\n",
      "Fit ARIMA: order=(1, 1, 1) seasonal_order=(1, 1, 0, 12); AIC=460.732, BIC=465.954, Fit time=0.530 seconds\n",
      "Fit ARIMA: order=(1, 1, 1) seasonal_order=(0, 1, 1, 12); AIC=nan, BIC=nan, Fit time=nan seconds\n",
      "Fit ARIMA: order=(1, 1, 1) seasonal_order=(1, 1, 1, 12); AIC=nan, BIC=nan, Fit time=nan seconds\n",
      "Fit ARIMA: order=(0, 1, 1) seasonal_order=(0, 1, 0, 12); AIC=463.037, BIC=466.171, Fit time=0.029 seconds\n",
      "Fit ARIMA: order=(2, 1, 1) seasonal_order=(0, 1, 0, 12); AIC=463.565, BIC=468.788, Fit time=0.105 seconds\n",
      "Fit ARIMA: order=(1, 1, 2) seasonal_order=(0, 1, 0, 12); AIC=460.756, BIC=465.979, Fit time=0.262 seconds\n",
      "Total fit time: 1.609 seconds\n",
      "Fit ARIMA: order=(0, 1, 0) seasonal_order=(0, 1, 1, 12); AIC=nan, BIC=nan, Fit time=nan seconds\n",
      "Fit ARIMA: order=(0, 1, 0) seasonal_order=(0, 1, 0, 12); AIC=662.108, BIC=664.910, Fit time=0.008 seconds\n",
      "Fit ARIMA: order=(1, 1, 0) seasonal_order=(1, 1, 0, 12); AIC=650.940, BIC=656.545, Fit time=0.067 seconds\n",
      "Fit ARIMA: order=(0, 1, 1) seasonal_order=(0, 1, 1, 12); AIC=nan, BIC=nan, Fit time=nan seconds\n",
      "Fit ARIMA: order=(1, 1, 0) seasonal_order=(0, 1, 0, 12); AIC=651.956, BIC=656.160, Fit time=0.022 seconds\n",
      "Fit ARIMA: order=(1, 1, 0) seasonal_order=(2, 1, 0, 12); AIC=645.423, BIC=652.429, Fit time=0.233 seconds\n",
      "Fit ARIMA: order=(1, 1, 0) seasonal_order=(2, 1, 1, 12); AIC=nan, BIC=nan, Fit time=nan seconds\n",
      "Fit ARIMA: order=(0, 1, 0) seasonal_order=(2, 1, 0, 12); AIC=655.038, BIC=660.643, Fit time=0.140 seconds\n",
      "Fit ARIMA: order=(2, 1, 0) seasonal_order=(2, 1, 0, 12); AIC=645.513, BIC=653.920, Fit time=0.261 seconds\n",
      "Fit ARIMA: order=(1, 1, 1) seasonal_order=(2, 1, 0, 12); AIC=644.398, BIC=652.805, Fit time=0.280 seconds\n",
      "Fit ARIMA: order=(2, 1, 2) seasonal_order=(2, 1, 0, 12); AIC=648.978, BIC=660.188, Fit time=1.161 seconds\n",
      "Fit ARIMA: order=(1, 1, 1) seasonal_order=(1, 1, 0, 12); AIC=649.871, BIC=656.877, Fit time=0.118 seconds\n",
      "Fit ARIMA: order=(1, 1, 1) seasonal_order=(2, 1, 1, 12); AIC=nan, BIC=nan, Fit time=nan seconds\n",
      "Fit ARIMA: order=(0, 1, 1) seasonal_order=(2, 1, 0, 12); AIC=643.594, BIC=650.600, Fit time=0.192 seconds\n",
      "Fit ARIMA: order=(0, 1, 2) seasonal_order=(2, 1, 0, 12); AIC=645.637, BIC=654.044, Fit time=0.235 seconds\n",
      "Fit ARIMA: order=(1, 1, 2) seasonal_order=(2, 1, 0, 12); AIC=647.020, BIC=656.829, Fit time=0.853 seconds\n",
      "Fit ARIMA: order=(0, 1, 1) seasonal_order=(1, 1, 0, 12); AIC=648.955, BIC=654.560, Fit time=0.120 seconds\n",
      "Fit ARIMA: order=(0, 1, 1) seasonal_order=(2, 1, 1, 12); AIC=nan, BIC=nan, Fit time=nan seconds\n",
      "Total fit time: 3.710 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ankit.joshi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:165: ValueWarning:\n",
      "\n",
      "No frequency information was provided, so inferred frequency MS will be used.\n",
      "\n",
      "C:\\Users\\ankit.joshi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:165: ValueWarning:\n",
      "\n",
      "No frequency information was provided, so inferred frequency MS will be used.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250ML\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ankit.joshi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:5096: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n",
      "INFO:fbprophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
      "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      "C:\\Users\\ankit.joshi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pystan\\misc.py:399: FutureWarning:\n",
      "\n",
      "Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "\n",
      "INFO:fbprophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
      "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      "C:\\Users\\ankit.joshi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pystan\\misc.py:399: FutureWarning:\n",
      "\n",
      "Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit ARIMA: order=(0, 1, 0) seasonal_order=(0, 1, 1, 12); AIC=nan, BIC=nan, Fit time=nan seconds\n",
      "Fit ARIMA: order=(0, 1, 0) seasonal_order=(0, 1, 0, 12); AIC=480.058, BIC=482.147, Fit time=0.008 seconds\n",
      "Fit ARIMA: order=(1, 1, 0) seasonal_order=(1, 1, 0, 12); AIC=478.133, BIC=482.311, Fit time=0.054 seconds\n",
      "Fit ARIMA: order=(0, 1, 1) seasonal_order=(0, 1, 1, 12); AIC=nan, BIC=nan, Fit time=nan seconds\n",
      "Fit ARIMA: order=(1, 1, 0) seasonal_order=(0, 1, 0, 12); AIC=479.007, BIC=482.141, Fit time=0.022 seconds\n",
      "Fit ARIMA: order=(1, 1, 0) seasonal_order=(2, 1, 0, 12); AIC=nan, BIC=nan, Fit time=nan seconds\n",
      "Fit ARIMA: order=(1, 1, 0) seasonal_order=(1, 1, 1, 12); AIC=nan, BIC=nan, Fit time=nan seconds\n",
      "Fit ARIMA: order=(1, 1, 0) seasonal_order=(2, 1, 1, 12); AIC=nan, BIC=nan, Fit time=nan seconds\n",
      "Fit ARIMA: order=(0, 1, 0) seasonal_order=(1, 1, 0, 12); AIC=479.402, BIC=482.536, Fit time=0.041 seconds\n",
      "Fit ARIMA: order=(2, 1, 0) seasonal_order=(1, 1, 0, 12); AIC=479.884, BIC=485.106, Fit time=0.085 seconds\n",
      "Fit ARIMA: order=(1, 1, 1) seasonal_order=(1, 1, 0, 12); AIC=480.295, BIC=485.518, Fit time=0.146 seconds\n",
      "Fit ARIMA: order=(2, 1, 1) seasonal_order=(1, 1, 0, 12); AIC=481.366, BIC=487.634, Fit time=0.271 seconds\n",
      "Total fit time: 0.637 seconds\n",
      "Fit ARIMA: order=(0, 1, 0) seasonal_order=(0, 1, 1, 12); AIC=nan, BIC=nan, Fit time=nan seconds\n",
      "Fit ARIMA: order=(0, 1, 0) seasonal_order=(0, 1, 0, 12); AIC=686.969, BIC=689.771, Fit time=0.008 seconds\n",
      "Fit ARIMA: order=(1, 1, 0) seasonal_order=(1, 1, 0, 12); AIC=684.159, BIC=689.764, Fit time=0.058 seconds\n",
      "Fit ARIMA: order=(0, 1, 1) seasonal_order=(0, 1, 1, 12); AIC=nan, BIC=nan, Fit time=nan seconds\n",
      "Fit ARIMA: order=(1, 1, 0) seasonal_order=(0, 1, 0, 12); AIC=685.494, BIC=689.698, Fit time=0.023 seconds\n",
      "Fit ARIMA: order=(1, 1, 0) seasonal_order=(2, 1, 0, 12); AIC=683.401, BIC=690.407, Fit time=0.286 seconds\n",
      "Fit ARIMA: order=(1, 1, 0) seasonal_order=(2, 1, 1, 12); AIC=nan, BIC=nan, Fit time=nan seconds\n",
      "Fit ARIMA: order=(0, 1, 0) seasonal_order=(2, 1, 0, 12); AIC=685.827, BIC=691.432, Fit time=0.217 seconds\n",
      "Fit ARIMA: order=(2, 1, 0) seasonal_order=(2, 1, 0, 12); AIC=685.271, BIC=693.678, Fit time=0.389 seconds\n",
      "Fit ARIMA: order=(1, 1, 1) seasonal_order=(2, 1, 0, 12); AIC=685.488, BIC=693.895, Fit time=0.635 seconds\n",
      "Fit ARIMA: order=(2, 1, 1) seasonal_order=(2, 1, 0, 12); AIC=686.803, BIC=696.611, Fit time=0.614 seconds\n",
      "Total fit time: 2.242 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ankit.joshi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:165: ValueWarning:\n",
      "\n",
      "No frequency information was provided, so inferred frequency MS will be used.\n",
      "\n",
      "C:\\Users\\ankit.joshi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:165: ValueWarning:\n",
      "\n",
      "No frequency information was provided, so inferred frequency MS will be used.\n",
      "\n",
      "C:\\Users\\ankit.joshi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:762: FutureWarning:\n",
      "\n",
      "Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "\n",
      "C:\\Users\\ankit.joshi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:5096: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n",
      "INFO:fbprophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0L\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      "C:\\Users\\ankit.joshi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pystan\\misc.py:399: FutureWarning:\n",
      "\n",
      "Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "\n",
      "INFO:fbprophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
      "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      "C:\\Users\\ankit.joshi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pystan\\misc.py:399: FutureWarning:\n",
      "\n",
      "Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit ARIMA: order=(0, 1, 0) seasonal_order=(0, 1, 1, 12); AIC=nan, BIC=nan, Fit time=nan seconds\n",
      "Fit ARIMA: order=(0, 1, 0) seasonal_order=(0, 1, 0, 12); AIC=420.045, BIC=422.134, Fit time=0.009 seconds\n",
      "Fit ARIMA: order=(1, 1, 0) seasonal_order=(1, 1, 0, 12); AIC=415.398, BIC=419.576, Fit time=0.068 seconds\n",
      "Fit ARIMA: order=(0, 1, 1) seasonal_order=(0, 1, 1, 12); AIC=nan, BIC=nan, Fit time=nan seconds\n",
      "Fit ARIMA: order=(1, 1, 0) seasonal_order=(0, 1, 0, 12); AIC=419.241, BIC=422.375, Fit time=0.019 seconds\n",
      "Fit ARIMA: order=(1, 1, 0) seasonal_order=(2, 1, 0, 12); AIC=nan, BIC=nan, Fit time=nan seconds\n",
      "Fit ARIMA: order=(1, 1, 0) seasonal_order=(1, 1, 1, 12); AIC=nan, BIC=nan, Fit time=nan seconds\n",
      "Fit ARIMA: order=(1, 1, 0) seasonal_order=(2, 1, 1, 12); AIC=nan, BIC=nan, Fit time=nan seconds\n",
      "Fit ARIMA: order=(0, 1, 0) seasonal_order=(1, 1, 0, 12); AIC=415.483, BIC=418.616, Fit time=0.062 seconds\n",
      "Fit ARIMA: order=(2, 1, 0) seasonal_order=(1, 1, 0, 12); AIC=414.433, BIC=419.656, Fit time=0.114 seconds\n",
      "Fit ARIMA: order=(2, 1, 1) seasonal_order=(1, 1, 0, 12); AIC=415.999, BIC=422.266, Fit time=0.129 seconds\n",
      "Fit ARIMA: order=(3, 1, 1) seasonal_order=(1, 1, 0, 12); AIC=412.719, BIC=420.031, Fit time=0.595 seconds\n",
      "Fit ARIMA: order=(3, 1, 1) seasonal_order=(0, 1, 0, 12); AIC=421.395, BIC=427.662, Fit time=0.064 seconds\n",
      "Fit ARIMA: order=(3, 1, 1) seasonal_order=(2, 1, 0, 12); AIC=nan, BIC=nan, Fit time=nan seconds\n",
      "Fit ARIMA: order=(3, 1, 1) seasonal_order=(1, 1, 1, 12); AIC=nan, BIC=nan, Fit time=nan seconds\n",
      "Fit ARIMA: order=(3, 1, 1) seasonal_order=(2, 1, 1, 12); AIC=nan, BIC=nan, Fit time=nan seconds\n",
      "Fit ARIMA: order=(4, 1, 1) seasonal_order=(1, 1, 0, 12); AIC=417.330, BIC=425.686, Fit time=0.305 seconds\n",
      "Fit ARIMA: order=(3, 1, 0) seasonal_order=(1, 1, 0, 12); AIC=411.741, BIC=418.008, Fit time=0.303 seconds\n",
      "Fit ARIMA: order=(3, 1, 0) seasonal_order=(0, 1, 0, 12); AIC=419.591, BIC=424.814, Fit time=0.040 seconds\n",
      "Fit ARIMA: order=(3, 1, 0) seasonal_order=(2, 1, 0, 12); AIC=nan, BIC=nan, Fit time=nan seconds\n",
      "Fit ARIMA: order=(3, 1, 0) seasonal_order=(1, 1, 1, 12); AIC=nan, BIC=nan, Fit time=nan seconds\n",
      "Fit ARIMA: order=(3, 1, 0) seasonal_order=(2, 1, 1, 12); AIC=nan, BIC=nan, Fit time=nan seconds\n",
      "Fit ARIMA: order=(4, 1, 0) seasonal_order=(1, 1, 0, 12); AIC=418.421, BIC=425.733, Fit time=0.196 seconds\n",
      "Total fit time: 1.931 seconds\n",
      "Fit ARIMA: order=(0, 1, 0) seasonal_order=(0, 1, 1, 12); AIC=nan, BIC=nan, Fit time=nan seconds\n",
      "Fit ARIMA: order=(0, 1, 0) seasonal_order=(0, 1, 0, 12); AIC=594.469, BIC=597.271, Fit time=0.010 seconds\n",
      "Fit ARIMA: order=(1, 1, 0) seasonal_order=(1, 1, 0, 12); AIC=589.620, BIC=595.225, Fit time=0.056 seconds\n",
      "Fit ARIMA: order=(0, 1, 1) seasonal_order=(0, 1, 1, 12); AIC=nan, BIC=nan, Fit time=nan seconds\n",
      "Fit ARIMA: order=(1, 1, 0) seasonal_order=(0, 1, 0, 12); AIC=592.257, BIC=596.461, Fit time=0.021 seconds\n",
      "Fit ARIMA: order=(1, 1, 0) seasonal_order=(2, 1, 0, 12); AIC=591.476, BIC=598.482, Fit time=0.178 seconds\n",
      "Fit ARIMA: order=(1, 1, 0) seasonal_order=(1, 1, 1, 12); AIC=nan, BIC=nan, Fit time=nan seconds\n",
      "Fit ARIMA: order=(1, 1, 0) seasonal_order=(2, 1, 1, 12); AIC=nan, BIC=nan, Fit time=nan seconds\n",
      "Fit ARIMA: order=(0, 1, 0) seasonal_order=(1, 1, 0, 12); AIC=591.247, BIC=595.451, Fit time=0.046 seconds\n",
      "Fit ARIMA: order=(2, 1, 0) seasonal_order=(1, 1, 0, 12); AIC=587.647, BIC=594.653, Fit time=0.093 seconds\n",
      "Fit ARIMA: order=(2, 1, 1) seasonal_order=(1, 1, 0, 12); AIC=589.159, BIC=597.566, Fit time=0.140 seconds\n",
      "Fit ARIMA: order=(3, 1, 1) seasonal_order=(1, 1, 0, 12); AIC=590.221, BIC=600.029, Fit time=0.323 seconds\n",
      "Fit ARIMA: order=(2, 1, 0) seasonal_order=(0, 1, 0, 12); AIC=590.947, BIC=596.552, Fit time=0.038 seconds\n",
      "Fit ARIMA: order=(2, 1, 0) seasonal_order=(2, 1, 0, 12); AIC=589.372, BIC=597.779, Fit time=0.220 seconds\n",
      "Fit ARIMA: order=(2, 1, 0) seasonal_order=(1, 1, 1, 12); AIC=nan, BIC=nan, Fit time=nan seconds\n",
      "Fit ARIMA: order=(2, 1, 0) seasonal_order=(2, 1, 1, 12); AIC=nan, BIC=nan, Fit time=nan seconds\n",
      "Fit ARIMA: order=(3, 1, 0) seasonal_order=(1, 1, 0, 12); AIC=588.348, BIC=596.756, Fit time=0.123 seconds\n",
      "Total fit time: 1.264 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ankit.joshi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:165: ValueWarning:\n",
      "\n",
      "No frequency information was provided, so inferred frequency MS will be used.\n",
      "\n",
      "C:\\Users\\ankit.joshi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:165: ValueWarning:\n",
      "\n",
      "No frequency information was provided, so inferred frequency MS will be used.\n",
      "\n",
      "C:\\Users\\ankit.joshi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:762: FutureWarning:\n",
      "\n",
      "Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375ML\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ankit.joshi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:5096: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n",
      "INFO:fbprophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
      "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      "C:\\Users\\ankit.joshi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pystan\\misc.py:399: FutureWarning:\n",
      "\n",
      "Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "\n",
      "INFO:fbprophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
      "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      "C:\\Users\\ankit.joshi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pystan\\misc.py:399: FutureWarning:\n",
      "\n",
      "Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit ARIMA: order=(0, 1, 0) seasonal_order=(0, 1, 1, 12); AIC=nan, BIC=nan, Fit time=nan seconds\n",
      "Fit ARIMA: order=(0, 1, 0) seasonal_order=(0, 1, 0, 12); AIC=520.460, BIC=522.549, Fit time=0.011 seconds\n",
      "Fit ARIMA: order=(1, 1, 0) seasonal_order=(1, 1, 0, 12); AIC=520.514, BIC=524.692, Fit time=0.062 seconds\n",
      "Fit ARIMA: order=(0, 1, 1) seasonal_order=(0, 1, 1, 12); AIC=nan, BIC=nan, Fit time=nan seconds\n",
      "Fit ARIMA: order=(0, 1, 0) seasonal_order=(1, 1, 0, 12); AIC=520.814, BIC=523.948, Fit time=0.072 seconds\n",
      "Fit ARIMA: order=(0, 1, 0) seasonal_order=(1, 1, 1, 12); AIC=nan, BIC=nan, Fit time=nan seconds\n",
      "Fit ARIMA: order=(1, 1, 0) seasonal_order=(0, 1, 0, 12); AIC=520.041, BIC=523.174, Fit time=0.118 seconds\n",
      "Fit ARIMA: order=(1, 1, 1) seasonal_order=(0, 1, 0, 12); AIC=526.176, BIC=530.354, Fit time=0.192 seconds\n",
      "Fit ARIMA: order=(2, 1, 1) seasonal_order=(0, 1, 0, 12); AIC=526.926, BIC=532.149, Fit time=0.379 seconds\n",
      "Fit ARIMA: order=(1, 1, 0) seasonal_order=(0, 1, 1, 12); AIC=nan, BIC=nan, Fit time=nan seconds\n",
      "Fit ARIMA: order=(1, 1, 0) seasonal_order=(1, 1, 1, 12); AIC=nan, BIC=nan, Fit time=nan seconds\n",
      "Fit ARIMA: order=(2, 1, 0) seasonal_order=(0, 1, 0, 12); AIC=524.090, BIC=528.269, Fit time=0.034 seconds\n",
      "Total fit time: 0.881 seconds\n",
      "Fit ARIMA: order=(0, 1, 0) seasonal_order=(0, 1, 1, 12); AIC=nan, BIC=nan, Fit time=nan seconds\n",
      "Fit ARIMA: order=(0, 1, 0) seasonal_order=(0, 1, 0, 12); AIC=734.234, BIC=737.037, Fit time=0.010 seconds\n",
      "Fit ARIMA: order=(1, 1, 0) seasonal_order=(1, 1, 0, 12); AIC=733.424, BIC=739.029, Fit time=0.126 seconds\n",
      "Fit ARIMA: order=(0, 1, 1) seasonal_order=(0, 1, 1, 12); AIC=nan, BIC=nan, Fit time=nan seconds\n",
      "Fit ARIMA: order=(1, 1, 0) seasonal_order=(0, 1, 0, 12); AIC=733.227, BIC=737.431, Fit time=0.051 seconds\n",
      "Fit ARIMA: order=(1, 1, 0) seasonal_order=(0, 1, 1, 12); AIC=nan, BIC=nan, Fit time=nan seconds\n",
      "Fit ARIMA: order=(1, 1, 0) seasonal_order=(1, 1, 1, 12); AIC=nan, BIC=nan, Fit time=nan seconds\n",
      "Fit ARIMA: order=(2, 1, 0) seasonal_order=(0, 1, 0, 12); AIC=736.331, BIC=741.936, Fit time=0.066 seconds\n",
      "Fit ARIMA: order=(1, 1, 1) seasonal_order=(0, 1, 0, 12); AIC=736.539, BIC=742.144, Fit time=0.226 seconds\n",
      "Fit ARIMA: order=(2, 1, 1) seasonal_order=(0, 1, 0, 12); AIC=738.472, BIC=745.478, Fit time=0.147 seconds\n",
      "Total fit time: 0.642 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ankit.joshi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:165: ValueWarning:\n",
      "\n",
      "No frequency information was provided, so inferred frequency MS will be used.\n",
      "\n",
      "C:\\Users\\ankit.joshi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\holtwinters.py:712: ConvergenceWarning:\n",
      "\n",
      "Optimization failed to converge. Check mle_retvals.\n",
      "\n",
      "C:\\Users\\ankit.joshi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:165: ValueWarning:\n",
      "\n",
      "No frequency information was provided, so inferred frequency MS will be used.\n",
      "\n",
      "C:\\Users\\ankit.joshi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\holtwinters.py:712: ConvergenceWarning:\n",
      "\n",
      "Optimization failed to converge. Check mle_retvals.\n",
      "\n",
      "C:\\Users\\ankit.joshi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:5096: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n",
      "INFO:fbprophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.0L\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      "INFO:fbprophet:n_changepoints greater than number of observations.Using 19.\n",
      "C:\\Users\\ankit.joshi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pystan\\misc.py:399: FutureWarning:\n",
      "\n",
      "Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "\n",
      "INFO:fbprophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
      "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      "INFO:fbprophet:n_changepoints greater than number of observations.Using 24.\n",
      "C:\\Users\\ankit.joshi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pystan\\misc.py:399: FutureWarning:\n",
      "\n",
      "Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit ARIMA: order=(0, 1, 0) seasonal_order=(0, 1, 1, 12); AIC=nan, BIC=nan, Fit time=nan seconds\n",
      "Fit ARIMA: order=(0, 1, 0) seasonal_order=(0, 1, 0, 12); AIC=220.323, BIC=221.293, Fit time=0.007 seconds\n",
      "Fit ARIMA: order=(1, 1, 0) seasonal_order=(1, 1, 0, 12); AIC=nan, BIC=nan, Fit time=nan seconds\n",
      "Fit ARIMA: order=(0, 1, 1) seasonal_order=(0, 1, 1, 12); AIC=nan, BIC=nan, Fit time=nan seconds\n",
      "Fit ARIMA: order=(0, 1, 0) seasonal_order=(1, 1, 0, 12); AIC=nan, BIC=nan, Fit time=nan seconds\n",
      "Fit ARIMA: order=(0, 1, 0) seasonal_order=(1, 1, 1, 12); AIC=nan, BIC=nan, Fit time=nan seconds\n",
      "Fit ARIMA: order=(1, 1, 0) seasonal_order=(0, 1, 0, 12); AIC=220.330, BIC=221.785, Fit time=0.049 seconds\n",
      "Fit ARIMA: order=(0, 1, 1) seasonal_order=(0, 1, 0, 12); AIC=217.595, BIC=219.050, Fit time=0.086 seconds\n",
      "Fit ARIMA: order=(1, 1, 2) seasonal_order=(0, 1, 0, 12); AIC=219.817, BIC=222.241, Fit time=0.151 seconds\n",
      "Fit ARIMA: order=(0, 1, 1) seasonal_order=(1, 1, 0, 12); AIC=nan, BIC=nan, Fit time=nan seconds\n",
      "Fit ARIMA: order=(0, 1, 1) seasonal_order=(1, 1, 1, 12); AIC=nan, BIC=nan, Fit time=nan seconds\n",
      "Fit ARIMA: order=(1, 1, 1) seasonal_order=(0, 1, 0, 12); AIC=219.348, BIC=221.288, Fit time=0.143 seconds\n",
      "Fit ARIMA: order=(0, 1, 2) seasonal_order=(0, 1, 0, 12); AIC=219.349, BIC=221.288, Fit time=0.158 seconds\n",
      "Total fit time: 0.611 seconds\n",
      "Fit ARIMA: order=(0, 1, 0) seasonal_order=(0, 1, 1, 12); AIC=nan, BIC=nan, Fit time=nan seconds\n",
      "Fit ARIMA: order=(0, 1, 0) seasonal_order=(0, 1, 0, 12); AIC=364.699, BIC=366.588, Fit time=0.009 seconds\n",
      "Fit ARIMA: order=(1, 1, 0) seasonal_order=(1, 1, 0, 12); AIC=366.424, BIC=370.201, Fit time=0.076 seconds\n",
      "Fit ARIMA: order=(0, 1, 1) seasonal_order=(0, 1, 1, 12); AIC=nan, BIC=nan, Fit time=nan seconds\n",
      "Fit ARIMA: order=(0, 1, 0) seasonal_order=(1, 1, 0, 12); AIC=365.042, BIC=367.875, Fit time=0.058 seconds\n",
      "Fit ARIMA: order=(0, 1, 0) seasonal_order=(1, 1, 1, 12); AIC=nan, BIC=nan, Fit time=nan seconds\n",
      "Fit ARIMA: order=(1, 1, 0) seasonal_order=(0, 1, 0, 12); AIC=365.473, BIC=368.307, Fit time=0.016 seconds\n",
      "Fit ARIMA: order=(0, 1, 1) seasonal_order=(0, 1, 0, 12); AIC=366.170, BIC=369.003, Fit time=0.026 seconds\n",
      "Fit ARIMA: order=(1, 1, 1) seasonal_order=(0, 1, 0, 12); AIC=367.918, BIC=371.696, Fit time=0.033 seconds\n",
      "Total fit time: 0.225 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ankit.joshi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:219: ValueWarning:\n",
      "\n",
      "A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "\n",
      "C:\\Users\\ankit.joshi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\holtwinters.py:712: ConvergenceWarning:\n",
      "\n",
      "Optimization failed to converge. Check mle_retvals.\n",
      "\n",
      "C:\\Users\\ankit.joshi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:576: ValueWarning:\n",
      "\n",
      "No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "\n",
      "C:\\Users\\ankit.joshi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:219: ValueWarning:\n",
      "\n",
      "A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "\n",
      "C:\\Users\\ankit.joshi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:576: ValueWarning:\n",
      "\n",
      "No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "\n",
      "C:\\Users\\ankit.joshi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:762: FutureWarning:\n",
      "\n",
      "Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "\n",
      "C:\\Users\\ankit.joshi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:5096: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n",
      "INFO:fbprophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500ML\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      "C:\\Users\\ankit.joshi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pystan\\misc.py:399: FutureWarning:\n",
      "\n",
      "Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "\n",
      "INFO:fbprophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
      "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      "C:\\Users\\ankit.joshi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pystan\\misc.py:399: FutureWarning:\n",
      "\n",
      "Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit ARIMA: order=(0, 1, 0) seasonal_order=(0, 1, 1, 12); AIC=nan, BIC=nan, Fit time=nan seconds\n",
      "Fit ARIMA: order=(0, 1, 0) seasonal_order=(0, 1, 0, 12); AIC=506.214, BIC=508.303, Fit time=0.010 seconds\n",
      "Fit ARIMA: order=(1, 1, 0) seasonal_order=(1, 1, 0, 12); AIC=510.285, BIC=514.463, Fit time=0.056 seconds\n",
      "Fit ARIMA: order=(0, 1, 1) seasonal_order=(0, 1, 1, 12); AIC=nan, BIC=nan, Fit time=nan seconds\n",
      "Fit ARIMA: order=(0, 1, 0) seasonal_order=(1, 1, 0, 12); AIC=508.129, BIC=511.263, Fit time=0.038 seconds\n",
      "Fit ARIMA: order=(0, 1, 0) seasonal_order=(1, 1, 1, 12); AIC=nan, BIC=nan, Fit time=nan seconds\n",
      "Fit ARIMA: order=(1, 1, 0) seasonal_order=(0, 1, 0, 12); AIC=508.372, BIC=511.505, Fit time=0.024 seconds\n",
      "Fit ARIMA: order=(0, 1, 1) seasonal_order=(0, 1, 0, 12); AIC=513.104, BIC=516.237, Fit time=0.047 seconds\n",
      "Fit ARIMA: order=(1, 1, 1) seasonal_order=(0, 1, 0, 12); AIC=515.787, BIC=519.965, Fit time=0.101 seconds\n",
      "Total fit time: 0.283 seconds\n",
      "Fit ARIMA: order=(0, 1, 0) seasonal_order=(0, 1, 1, 12); AIC=nan, BIC=nan, Fit time=nan seconds\n",
      "Fit ARIMA: order=(0, 1, 0) seasonal_order=(0, 1, 0, 12); AIC=734.055, BIC=736.858, Fit time=0.009 seconds\n",
      "Fit ARIMA: order=(1, 1, 0) seasonal_order=(1, 1, 0, 12); AIC=738.005, BIC=743.610, Fit time=0.070 seconds\n",
      "Fit ARIMA: order=(0, 1, 1) seasonal_order=(0, 1, 1, 12); AIC=nan, BIC=nan, Fit time=nan seconds\n",
      "Fit ARIMA: order=(0, 1, 0) seasonal_order=(1, 1, 0, 12); AIC=735.909, BIC=740.113, Fit time=0.057 seconds\n",
      "Fit ARIMA: order=(0, 1, 0) seasonal_order=(1, 1, 1, 12); AIC=nan, BIC=nan, Fit time=nan seconds\n",
      "Fit ARIMA: order=(1, 1, 0) seasonal_order=(0, 1, 0, 12); AIC=736.142, BIC=740.345, Fit time=0.029 seconds\n",
      "Fit ARIMA: order=(0, 1, 1) seasonal_order=(0, 1, 0, 12); AIC=736.321, BIC=740.525, Fit time=0.029 seconds\n",
      "Fit ARIMA: order=(1, 1, 1) seasonal_order=(0, 1, 0, 12); AIC=738.539, BIC=744.144, Fit time=0.086 seconds\n",
      "Total fit time: 0.287 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ankit.joshi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:165: ValueWarning:\n",
      "\n",
      "No frequency information was provided, so inferred frequency MS will be used.\n",
      "\n",
      "C:\\Users\\ankit.joshi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:165: ValueWarning:\n",
      "\n",
      "No frequency information was provided, so inferred frequency MS will be used.\n",
      "\n",
      "C:\\Users\\ankit.joshi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:5096: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n",
      "INFO:werkzeug:127.0.0.1 - - [15/Aug/2019 11:05:10] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750ML\n"
     ]
    }
   ],
   "source": [
    "@app.route('/', methods=['GET', 'POST'])\n",
    "def index():\n",
    "    masterfile=pd.read_excel(r\"privatedata\\ValidMasterCodes.xlsx\")\n",
    "    mastercodes=list(masterfile.MASTER.values)\n",
    "    masterdata=pd.read_excel(r\"privatedata\\MasterData.xlsx\")\n",
    "    if request.method == 'GET':\n",
    "        return render_template('index.html')\n",
    "    elif request.method == 'POST':\n",
    "        if request.form['action'] == 'Generate':\n",
    "            inputmethod=request.form.get('InputMethod')\n",
    "            model=request.form.get('Model')\n",
    "            aggregator=request.form.get('AggregateBy')\n",
    "            startdate=request.form.get('startdate')+'-01'\n",
    "            enddate=request.form.get('enddate')+'-01'\n",
    "            period=request.form.get('period')\n",
    "            print(inputmethod)\n",
    "            print(model)\n",
    "            print(aggregator)\n",
    "            print(startdate)\n",
    "            print(enddate)\n",
    "            print(period)\n",
    "            ####################################    SQL    #######################################################\n",
    "            if inputmethod.strip()=='sql' and aggregator.strip()=='mastercode':\n",
    "                \n",
    "                curr=conn.cursor()\n",
    "                \n",
    "                curr.execute(\"select * from shipments\")\n",
    "                quantity=curr.fetchall()\n",
    "                data=pd.DataFrame(quantity,columns=['Group','Month','Total'])\n",
    "\n",
    "                if model.strip()=='bestfit':\n",
    "                    finaldf=pd.DataFrame()\n",
    "                    mape=pd.DataFrame()\n",
    "                    model=pd.DataFrame()\n",
    "                    columnhead=[]\n",
    "\n",
    "                    for master in mastercodes:\n",
    "                        count=0\n",
    "                        flag=''\n",
    "                        cleandata,originaldata=iterateclean(data,master,startdate,enddate)\n",
    "                        if len(originaldata)>12 and int(max(originaldata.index).strftime(\"%Y\"))==2019:\n",
    "                            try:\n",
    "                                prophet_out,prophet_mape=prophet_forecast(cleandata,originaldata,int(period))\n",
    "                                flag+='a'\n",
    "                            except:\n",
    "                                count+=1\n",
    "                                pass\n",
    "                            try:\n",
    "                                arima_out,arima_mape=arima_forecast(cleandata,originaldata,int(period))\n",
    "                                flag+='b'\n",
    "                            except:\n",
    "                                count+=1\n",
    "                                pass\n",
    "                            try:\n",
    "                                ets_out,ets_mape=ets_forecast(cleandata,originaldata,int(period))\n",
    "                                flag+='c'\n",
    "                            except:\n",
    "                                count+=1\n",
    "                                pass\n",
    "                        else:\n",
    "                            continue\n",
    "                        print(master)\n",
    "                        if count<3:\n",
    "                            if count==2:\n",
    "                                if flag=='a':\n",
    "                                    best=0\n",
    "                                elif flag=='b':\n",
    "                                    best=1\n",
    "                                elif flag=='c':\n",
    "                                    best=2\n",
    "                            elif count==1:\n",
    "                                if flag=='ab':\n",
    "                                    best=min_mape(prophet_mape,arima_mape)\n",
    "                                elif flag=='bc':\n",
    "                                    best=min_mape(arima_mape,ets_mape)+1\n",
    "                                elif flag=='ac':\n",
    "                                    best=min_mape(prophet_mape,ets_mape)\n",
    "                                    if best==1:\n",
    "                                        best+=1\n",
    "                            elif count==0:\n",
    "                                best=min_mape(prophet_mape,arima_mape,ets_mape)\n",
    "                            if best==0:\n",
    "                                model[master]=['Prophet']\n",
    "                                mape[master]=[prophet_mape]\n",
    "                                try:\n",
    "                                    finaldf=pd.concat([finaldf,prophet_out], ignore_index=True, axis=1)\n",
    "                                    columnhead.append(master)\n",
    "                                except:\n",
    "                                    continue\n",
    "                            elif best==1:\n",
    "                                model[master]=['ARIMA']\n",
    "                                mape[master]=[arima_mape]\n",
    "                                try:\n",
    "                                    finaldf=pd.concat([finaldf,arima_out], ignore_index=True, axis=1)\n",
    "                                    columnhead.append(master)\n",
    "                                except:\n",
    "                                    continue\n",
    "                            elif best==2:\n",
    "                                model[master]=['ETS']\n",
    "                                mape[master]=[ets_mape]\n",
    "                                try:\n",
    "                                    finaldf=pd.concat([finaldf,ets_out], ignore_index=True, axis=1)\n",
    "                                    columnhead.append(master)\n",
    "                                except:\n",
    "                                    continue\n",
    "                            else:\n",
    "                                continue\n",
    "                        else:\n",
    "                            continue\n",
    "\n",
    "                    finaldf.columns=columnhead\n",
    "                    mape=mape.transpose()\n",
    "                    model=model.transpose()\n",
    "                    mape.columns=['Mape']\n",
    "                    model.columns=['Model']\n",
    "                    exportdf=finaldf.transpose()\n",
    "                    exportdf[\"Model\"]=model.Model\n",
    "                    exportdf['Mape']=mape.Mape\n",
    "                    exportdf.to_excel(\"forecastsheet.xlsx\")\n",
    "\n",
    "                    return send_file('forecastsheet.xlsx', attachment_filename='forecastsheet.xlsx')\n",
    "\n",
    "                elif model.strip()=='prophet':\n",
    "                    finaldf=pd.DataFrame()\n",
    "                    mape=pd.DataFrame()\n",
    "                    model=pd.DataFrame()\n",
    "                    columnhead=[]\n",
    "\n",
    "                    for master in mastercodes:\n",
    "                        cleandata,originaldata=iterateclean(data,master,startdate,enddate)\n",
    "                        if len(originaldata)>12 and int(max(originaldata.index).strftime(\"%Y\"))==2019:\n",
    "                            try:\n",
    "                                prophet_out,prophet_mape=prophet_forecast(cleandata,originaldata,int(period))\n",
    "                            except:\n",
    "                                pass\n",
    "                        else:\n",
    "                            continue\n",
    "\n",
    "                        try:\n",
    "                            finaldf=pd.concat([finaldf,prophet_out], ignore_index=True, axis=1)\n",
    "                            columnhead.append(master)\n",
    "                        except:\n",
    "                            continue\n",
    "                        model[master]=['Prophet']\n",
    "                        mape[master]=[prophet_mape]\n",
    "\n",
    "                    finaldf.columns=columnhead\n",
    "                    mape=mape.transpose()\n",
    "                    model=model.transpose()\n",
    "                    mape.columns=['Mape']\n",
    "                    model.columns=['Model']\n",
    "                    exportdf=finaldf.transpose()\n",
    "                    exportdf[\"Model\"]=model.Model\n",
    "                    exportdf['Mape']=mape.Mape\n",
    "                    exportdf.to_excel(\"forecastsheet.xlsx\")\n",
    "\n",
    "                    return send_file('forecastsheet.xlsx', attachment_filename='forecastsheet.xlsx')\n",
    "                \n",
    "                elif model.strip()=='arima':\n",
    "                    finaldf=pd.DataFrame()\n",
    "                    mape=pd.DataFrame()\n",
    "                    model=pd.DataFrame()\n",
    "                    columnhead=[]\n",
    "\n",
    "                    for master in mastercodes:\n",
    "                        cleandata,originaldata=iterateclean(data,master,startdate,enddate)\n",
    "                        if len(originaldata)>12 and int(max(originaldata.index).strftime(\"%Y\"))==2019:\n",
    "                            try:\n",
    "                                arima_out,arima_mape=arima_forecast(cleandata,originaldata,int(period))\n",
    "                            except:\n",
    "                                pass\n",
    "                        else:\n",
    "                            continue\n",
    "\n",
    "                        try:\n",
    "                            finaldf=pd.concat([finaldf,arima_out], ignore_index=True, axis=1)\n",
    "                            columnhead.append(master)\n",
    "                        except:\n",
    "                            continue\n",
    "                        model[master]=['ARIMA']\n",
    "                        mape[master]=[arima_mape]\n",
    "\n",
    "                    finaldf.columns=columnhead\n",
    "                    mape=mape.transpose()\n",
    "                    model=model.transpose()\n",
    "                    mape.columns=['Mape']\n",
    "                    model.columns=['Model']\n",
    "                    exportdf=finaldf.transpose()\n",
    "                    exportdf[\"Model\"]=model.Model\n",
    "                    exportdf['Mape']=mape.Mape\n",
    "                    exportdf.to_excel(\"forecastsheet.xlsx\")\n",
    "\n",
    "                    return send_file('forecastsheet.xlsx', attachment_filename='forecastsheet.xlsx')                \n",
    "        \n",
    "        \n",
    "                elif model.strip()=='ets':\n",
    "                    finaldf=pd.DataFrame()\n",
    "                    mape=pd.DataFrame()\n",
    "                    model=pd.DataFrame()\n",
    "                    columnhead=[]\n",
    "\n",
    "                    for master in mastercodes:\n",
    "                        cleandata,originaldata=iterateclean(data,master,startdate,enddate)\n",
    "                        if len(originaldata)>12 and int(max(originaldata.index).strftime(\"%Y\"))==2019:\n",
    "                            try:\n",
    "                                ets_out,ets_mape=ets_forecast(cleandata,originaldata,int(period))\n",
    "                            except:\n",
    "                                pass\n",
    "                        else:\n",
    "                            continue\n",
    "\n",
    "                        try:\n",
    "                            finaldf=pd.concat([finaldf,ets_out], ignore_index=True, axis=1)\n",
    "                            columnhead.append(master)\n",
    "                        except:\n",
    "                            continue\n",
    "                        model[master]=['ETS']\n",
    "                        mape[master]=[ets_mape]\n",
    "\n",
    "                    finaldf.columns=columnhead\n",
    "                    mape=mape.transpose()\n",
    "                    model=model.transpose()\n",
    "                    mape.columns=['Mape']\n",
    "                    model.columns=['Model']\n",
    "                    exportdf=finaldf.transpose()\n",
    "                    exportdf[\"Model\"]=model.Model\n",
    "                    exportdf['Mape']=mape.Mape\n",
    "                    exportdf.to_excel(\"forecastsheet.xlsx\")\n",
    "\n",
    "                    return send_file('forecastsheet.xlsx', attachment_filename='forecastsheet.xlsx')\n",
    "\n",
    "######################################################  CSV   ##############################################################\n",
    "            \n",
    "    \n",
    "            if inputmethod.strip()=='csv' and aggregator.strip()=='mastercode':\n",
    "                f = request.files['csvfile']\n",
    "                f.save(secure_filename(f.filename))\n",
    "                print(f.filename)\n",
    "                if str(f.filename).endswith('.csv'):\n",
    "                    data=pd.read_csv(\"%s\"%(secure_filename(f.filename)),encoding='latin')\n",
    "                    try:\n",
    "                        data=data[['Group','Month','Total']]\n",
    "                    except:\n",
    "                        return redirect(url_for('index'))\n",
    "                if str(f.filename).endswith('.xlsx') or str(f.filename).endswith('.xls'):\n",
    "                    data=pd.read_excel(\"%s\"%(secure_filename(f.filename)))\n",
    "                    try:\n",
    "                        data=data[['Group','Month','Total']]\n",
    "                    except:\n",
    "                        return redirect(url_for('index'))\n",
    "                if model.strip()=='bestfit':\n",
    "                    finaldf=pd.DataFrame()\n",
    "                    mape=pd.DataFrame()\n",
    "                    model=pd.DataFrame()\n",
    "                    columnhead=[]\n",
    "\n",
    "                    for master in mastercodes:\n",
    "                        count=0\n",
    "                        flag=''\n",
    "                        cleandata,originaldata=iterateclean(data,'Group',master,startdate,enddate)\n",
    "                        if len(originaldata)>12 and int(max(originaldata.index).strftime(\"%Y\"))==2019:\n",
    "                            try:\n",
    "                                prophet_out,prophet_mape=prophet_forecast(cleandata,originaldata,int(period))\n",
    "                                flag+='a'\n",
    "                            except:\n",
    "                                count+=1\n",
    "                                pass\n",
    "                            try:\n",
    "                                arima_out,arima_mape=arima_forecast(cleandata,originaldata,int(period))\n",
    "                                flag+='b'\n",
    "                            except:\n",
    "                                count+=1\n",
    "                                pass\n",
    "                            try:\n",
    "                                ets_out,ets_mape=ets_forecast(cleandata,originaldata,int(period))\n",
    "                                flag+='c'\n",
    "                            except:\n",
    "                                count+=1\n",
    "                                pass\n",
    "                        else:\n",
    "                            continue\n",
    "                        print(master)\n",
    "                        if count<3:\n",
    "                            if count==2:\n",
    "                                if flag=='a':\n",
    "                                    best=0\n",
    "                                elif flag=='b':\n",
    "                                    best=1\n",
    "                                elif flag=='c':\n",
    "                                    best=2\n",
    "                            elif count==1:\n",
    "                                if flag=='ab':\n",
    "                                    best=min_mape(prophet_mape,arima_mape)\n",
    "                                elif flag=='bc':\n",
    "                                    best=min_mape(arima_mape,ets_mape)+1\n",
    "                                elif flag=='ac':\n",
    "                                    best=min_mape(prophet_mape,ets_mape)\n",
    "                                    if best==1:\n",
    "                                        best+=1\n",
    "                            elif count==0:\n",
    "                                best=min_mape(prophet_mape,arima_mape,ets_mape)\n",
    "                            if best==0:\n",
    "                                model[master]=['Prophet']\n",
    "                                mape[master]=[prophet_mape]\n",
    "                                try:\n",
    "                                    finaldf=pd.concat([finaldf,prophet_out], ignore_index=True, axis=1)\n",
    "                                    columnhead.append(master)\n",
    "                                except:\n",
    "                                    continue\n",
    "                            elif best==1:\n",
    "                                model[master]=['ARIMA']\n",
    "                                mape[master]=[arima_mape]\n",
    "                                try:\n",
    "                                    finaldf=pd.concat([finaldf,arima_out], ignore_index=True, axis=1)\n",
    "                                    columnhead.append(master)\n",
    "                                except:\n",
    "                                    continue\n",
    "                            elif best==2:\n",
    "                                model[master]=['ETS']\n",
    "                                mape[master]=[ets_mape]\n",
    "                                try:\n",
    "                                    finaldf=pd.concat([finaldf,ets_out], ignore_index=True, axis=1)\n",
    "                                    columnhead.append(master)\n",
    "                                except:\n",
    "                                    continue\n",
    "                            else:\n",
    "                                continue\n",
    "                        else:\n",
    "                            continue\n",
    "\n",
    "                    finaldf.columns=columnhead\n",
    "                    mape=mape.transpose()\n",
    "                    model=model.transpose()\n",
    "                    mape.columns=['Mape']\n",
    "                    model.columns=['Model']\n",
    "                    exportdf=finaldf.transpose()\n",
    "                    exportdf[\"Model\"]=model.Model\n",
    "                    exportdf['Mape']=mape.Mape\n",
    "                    exportdf.to_excel(\"forecastsheet.xlsx\")\n",
    "\n",
    "                    return send_file('forecastsheet.xlsx', attachment_filename='forecastsheet.xlsx')\n",
    "\n",
    "                elif model.strip()=='prophet':\n",
    "                    finaldf=pd.DataFrame()\n",
    "                    mape=pd.DataFrame()\n",
    "                    model=pd.DataFrame()\n",
    "                    columnhead=[]\n",
    "\n",
    "                    for master in mastercodes:\n",
    "                        cleandata,originaldata=iterateclean(data,'Group',master,startdate,enddate)\n",
    "                        if len(originaldata)>12 and int(max(originaldata.index).strftime(\"%Y\"))==2019:\n",
    "                            try:\n",
    "                                prophet_out,prophet_mape=prophet_forecast(cleandata,originaldata,int(period))\n",
    "                            except:\n",
    "                                pass\n",
    "                        else:\n",
    "                            continue\n",
    "\n",
    "                        try:\n",
    "                            finaldf=pd.concat([finaldf,prophet_out], ignore_index=True, axis=1)\n",
    "                            columnhead.append(master)\n",
    "                        except:\n",
    "                            continue\n",
    "                        model[master]=['Prophet']\n",
    "                        mape[master]=[prophet_mape]\n",
    "\n",
    "                    finaldf.columns=columnhead\n",
    "                    mape=mape.transpose()\n",
    "                    model=model.transpose()\n",
    "                    mape.columns=['Mape']\n",
    "                    model.columns=['Model']\n",
    "                    exportdf=finaldf.transpose()\n",
    "                    exportdf[\"Model\"]=model.Model\n",
    "                    exportdf['Mape']=mape.Mape\n",
    "                    exportdf.to_excel(\"forecastsheet.xlsx\")\n",
    "\n",
    "                    return send_file('forecastsheet.xlsx', attachment_filename='forecastsheet.xlsx')\n",
    "                \n",
    "                elif model.strip()=='arima':\n",
    "                    finaldf=pd.DataFrame()\n",
    "                    mape=pd.DataFrame()\n",
    "                    model=pd.DataFrame()\n",
    "                    columnhead=[]\n",
    "\n",
    "                    for master in mastercodes:\n",
    "                        cleandata,originaldata=iterateclean(data,'Group',master,startdate,enddate)\n",
    "                        if len(originaldata)>12 and int(max(originaldata.index).strftime(\"%Y\"))==2019:\n",
    "                            try:\n",
    "                                arima_out,arima_mape=arima_forecast(cleandata,originaldata,int(period))\n",
    "                            except:\n",
    "                                pass\n",
    "                        else:\n",
    "                            continue\n",
    "\n",
    "                        try:\n",
    "                            finaldf=pd.concat([finaldf,arima_out], ignore_index=True, axis=1)\n",
    "                            columnhead.append(master)\n",
    "                        except:\n",
    "                            continue\n",
    "                        model[master]=['ARIMA']\n",
    "                        mape[master]=[arima_mape]\n",
    "\n",
    "                    finaldf.columns=columnhead\n",
    "                    mape=mape.transpose()\n",
    "                    model=model.transpose()\n",
    "                    mape.columns=['Mape']\n",
    "                    model.columns=['Model']\n",
    "                    exportdf=finaldf.transpose()\n",
    "                    exportdf[\"Model\"]=model.Model\n",
    "                    exportdf['Mape']=mape.Mape\n",
    "                    exportdf.to_excel(\"forecastsheet.xlsx\")\n",
    "\n",
    "                    return send_file('forecastsheet.xlsx', attachment_filename='forecastsheet.xlsx')                \n",
    "        \n",
    "        \n",
    "                elif model.strip()=='ets':\n",
    "                    finaldf=pd.DataFrame()\n",
    "                    mape=pd.DataFrame()\n",
    "                    model=pd.DataFrame()\n",
    "                    columnhead=[]\n",
    "\n",
    "                    for master in mastercodes:\n",
    "                        cleandata,originaldata=iterateclean(data,'Group',master,startdate,enddate)\n",
    "                        if len(originaldata)>12 and int(max(originaldata.index).strftime(\"%Y\"))==2019:\n",
    "                            try:\n",
    "                                ets_out,ets_mape=ets_forecast(cleandata,originaldata,int(period))\n",
    "                            except:\n",
    "                                pass\n",
    "                        else:\n",
    "                            continue\n",
    "\n",
    "                        try:\n",
    "                            finaldf=pd.concat([finaldf,ets_out], ignore_index=True, axis=1)\n",
    "                            columnhead.append(master)\n",
    "                        except:\n",
    "                            continue\n",
    "                        model[master]=['ETS']\n",
    "                        mape[master]=[ets_mape]\n",
    "\n",
    "                    finaldf.columns=columnhead\n",
    "                    mape=mape.transpose()\n",
    "                    model=model.transpose()\n",
    "                    mape.columns=['Mape']\n",
    "                    model.columns=['Model']\n",
    "                    exportdf=finaldf.transpose()\n",
    "                    exportdf[\"Model\"]=model.Model\n",
    "                    exportdf['Mape']=mape.Mape\n",
    "                    exportdf.to_excel(\"forecastsheet.xlsx\")\n",
    "\n",
    "                    return send_file('forecastsheet.xlsx', attachment_filename='forecastsheet.xlsx')\n",
    "       \n",
    "    ##################################################   aggregate by brand ##########################################\n",
    "            if inputmethod.strip()=='csv' and aggregator.strip()=='brand':\n",
    "                f = request.files['csvfile']\n",
    "                f.save(secure_filename(f.filename))\n",
    "                print(f.filename)\n",
    "                if str(f.filename).endswith('.csv'):\n",
    "                    data=pd.read_csv(\"%s\"%(secure_filename(f.filename)),encoding='latin')\n",
    "                    try:\n",
    "                        data=data[['Group','Month','Total']]\n",
    "                    except:\n",
    "                        return redirect(url_for('index'))\n",
    "                if str(f.filename).endswith('.xlsx') or str(f.filename).endswith('.xls'):\n",
    "                    data=pd.read_excel(\"%s\"%(secure_filename(f.filename)))\n",
    "                    try:\n",
    "                        data=data[['Group','Month','Total']]\n",
    "                    except:\n",
    "                        return redirect(url_for('index'))\n",
    "                    \n",
    "                joined=pd.merge(data, masterdata, left_on='Group',right_on='Cat Cd10 Description', how='left')   \n",
    "                bybrand=joined.groupby(['Brand Description','Month'])[['Total']].sum()    \n",
    "                bybrand.reset_index(inplace=True)\n",
    "                brands=list(bybrand['Brand Description'].unique())\n",
    "                    \n",
    "                if model.strip()=='bestfit':\n",
    "                    finaldf=pd.DataFrame()\n",
    "                    mape=pd.DataFrame()\n",
    "                    model=pd.DataFrame()\n",
    "                    columnhead=[]\n",
    "\n",
    "                    for master in brands:\n",
    "                        count=0\n",
    "                        flag=''\n",
    "                        cleandata,originaldata=iterateclean(bybrand,'Brand Description',master,startdate,enddate)\n",
    "                        if len(originaldata)>12 and int(max(originaldata.index).strftime(\"%Y\"))==2019:\n",
    "                            try:\n",
    "                                prophet_out,prophet_mape=prophet_forecast(cleandata,originaldata,int(period))\n",
    "                                flag+='a'\n",
    "                            except:\n",
    "                                count+=1\n",
    "                                pass\n",
    "                            try:\n",
    "                                arima_out,arima_mape=arima_forecast(cleandata,originaldata,int(period))\n",
    "                                flag+='b'\n",
    "                            except:\n",
    "                                count+=1\n",
    "                                pass\n",
    "                            try:\n",
    "                                ets_out,ets_mape=ets_forecast(cleandata,originaldata,int(period))\n",
    "                                flag+='c'\n",
    "                            except:\n",
    "                                count+=1\n",
    "                                pass\n",
    "                        else:\n",
    "                            continue\n",
    "                        print(master)\n",
    "                        if count<3:\n",
    "                            if count==2:\n",
    "                                if flag=='a':\n",
    "                                    best=0\n",
    "                                elif flag=='b':\n",
    "                                    best=1\n",
    "                                elif flag=='c':\n",
    "                                    best=2\n",
    "                            elif count==1:\n",
    "                                if flag=='ab':\n",
    "                                    best=min_mape(prophet_mape,arima_mape)\n",
    "                                elif flag=='bc':\n",
    "                                    best=min_mape(arima_mape,ets_mape)+1\n",
    "                                elif flag=='ac':\n",
    "                                    best=min_mape(prophet_mape,ets_mape)\n",
    "                                    if best==1:\n",
    "                                        best+=1\n",
    "                            elif count==0:\n",
    "                                best=min_mape(prophet_mape,arima_mape,ets_mape)\n",
    "                            if best==0:\n",
    "                                model[master]=['Prophet']\n",
    "                                mape[master]=[prophet_mape]\n",
    "                                try:\n",
    "                                    finaldf=pd.concat([finaldf,prophet_out], ignore_index=True, axis=1)\n",
    "                                    columnhead.append(master)\n",
    "                                except:\n",
    "                                    continue\n",
    "                            elif best==1:\n",
    "                                model[master]=['ARIMA']\n",
    "                                mape[master]=[arima_mape]\n",
    "                                try:\n",
    "                                    finaldf=pd.concat([finaldf,arima_out], ignore_index=True, axis=1)\n",
    "                                    columnhead.append(master)\n",
    "                                except:\n",
    "                                    continue\n",
    "                            elif best==2:\n",
    "                                model[master]=['ETS']\n",
    "                                mape[master]=[ets_mape]\n",
    "                                try:\n",
    "                                    finaldf=pd.concat([finaldf,ets_out], ignore_index=True, axis=1)\n",
    "                                    columnhead.append(master)\n",
    "                                except:\n",
    "                                    continue\n",
    "                            else:\n",
    "                                continue\n",
    "                        else:\n",
    "                            continue\n",
    "\n",
    "                    finaldf.columns=columnhead\n",
    "                    mape=mape.transpose()\n",
    "                    model=model.transpose()\n",
    "                    mape.columns=['Mape']\n",
    "                    model.columns=['Model']\n",
    "                    exportdf=finaldf.transpose()\n",
    "                    exportdf[\"Model\"]=model.Model\n",
    "                    exportdf['Mape']=mape.Mape\n",
    "                    exportdf.to_excel(\"forecastsheet.xlsx\")\n",
    "\n",
    "                    return send_file('forecastsheet.xlsx', attachment_filename='forecastsheet.xlsx')\n",
    "\n",
    "                elif model.strip()=='prophet':\n",
    "                    finaldf=pd.DataFrame()\n",
    "                    mape=pd.DataFrame()\n",
    "                    model=pd.DataFrame()\n",
    "                    columnhead=[]\n",
    "\n",
    "                    for master in brands:\n",
    "                        cleandata,originaldata=iterateclean(bybrand,'Brand Description',master,startdate,enddate)\n",
    "                        if len(originaldata)>12 and int(max(originaldata.index).strftime(\"%Y\"))==2019:\n",
    "                            try:\n",
    "                                prophet_out,prophet_mape=prophet_forecast(cleandata,originaldata,int(period))\n",
    "                            except:\n",
    "                                pass\n",
    "                        else:\n",
    "                            continue\n",
    "\n",
    "                        try:\n",
    "                            finaldf=pd.concat([finaldf,prophet_out], ignore_index=True, axis=1)\n",
    "                            columnhead.append(master)\n",
    "                        except:\n",
    "                            continue\n",
    "                        model[master]=['Prophet']\n",
    "                        mape[master]=[prophet_mape]\n",
    "\n",
    "                    finaldf.columns=columnhead\n",
    "                    mape=mape.transpose()\n",
    "                    model=model.transpose()\n",
    "                    mape.columns=['Mape']\n",
    "                    model.columns=['Model']\n",
    "                    exportdf=finaldf.transpose()\n",
    "                    exportdf[\"Model\"]=model.Model\n",
    "                    exportdf['Mape']=mape.Mape\n",
    "                    exportdf.to_excel(\"forecastsheet.xlsx\")\n",
    "\n",
    "                    return send_file('forecastsheet.xlsx', attachment_filename='forecastsheet.xlsx')\n",
    "                \n",
    "                elif model.strip()=='arima':\n",
    "                    finaldf=pd.DataFrame()\n",
    "                    mape=pd.DataFrame()\n",
    "                    model=pd.DataFrame()\n",
    "                    columnhead=[]\n",
    "\n",
    "                    for master in brands:\n",
    "                        cleandata,originaldata=iterateclean(bybrand,'Brand Description',master,startdate,enddate)\n",
    "                        if len(originaldata)>12 and int(max(originaldata.index).strftime(\"%Y\"))==2019:\n",
    "                            try:\n",
    "                                arima_out,arima_mape=arima_forecast(cleandata,originaldata,int(period))\n",
    "                            except:\n",
    "                                pass\n",
    "                        else:\n",
    "                            continue\n",
    "\n",
    "                        try:\n",
    "                            finaldf=pd.concat([finaldf,arima_out], ignore_index=True, axis=1)\n",
    "                            columnhead.append(master)\n",
    "                        except:\n",
    "                            continue\n",
    "                        model[master]=['ARIMA']\n",
    "                        mape[master]=[arima_mape]\n",
    "\n",
    "                    finaldf.columns=columnhead\n",
    "                    mape=mape.transpose()\n",
    "                    model=model.transpose()\n",
    "                    mape.columns=['Mape']\n",
    "                    model.columns=['Model']\n",
    "                    exportdf=finaldf.transpose()\n",
    "                    exportdf[\"Model\"]=model.Model\n",
    "                    exportdf['Mape']=mape.Mape\n",
    "                    exportdf.to_excel(\"forecastsheet.xlsx\")\n",
    "\n",
    "                    return send_file('forecastsheet.xlsx', attachment_filename='forecastsheet.xlsx')                \n",
    "        \n",
    "        \n",
    "                elif model.strip()=='ets':\n",
    "                    finaldf=pd.DataFrame()\n",
    "                    mape=pd.DataFrame()\n",
    "                    model=pd.DataFrame()\n",
    "                    columnhead=[]\n",
    "\n",
    "                    for master in brands:\n",
    "                        cleandata,originaldata=iterateclean(bybrand,'Brand Description',master,startdate,enddate)\n",
    "                        if len(originaldata)>12 and int(max(originaldata.index).strftime(\"%Y\"))==2019:\n",
    "                            try:\n",
    "                                ets_out,ets_mape=ets_forecast(cleandata,originaldata,int(period))\n",
    "                            except:\n",
    "                                pass\n",
    "                        else:\n",
    "                            continue\n",
    "\n",
    "                        try:\n",
    "                            finaldf=pd.concat([finaldf,ets_out], ignore_index=True, axis=1)\n",
    "                            columnhead.append(master)\n",
    "                        except:\n",
    "                            continue\n",
    "                        model[master]=['ETS']\n",
    "                        mape[master]=[ets_mape]\n",
    "\n",
    "                    finaldf.columns=columnhead\n",
    "                    mape=mape.transpose()\n",
    "                    model=model.transpose()\n",
    "                    mape.columns=['Mape']\n",
    "                    model.columns=['Model']\n",
    "                    exportdf=finaldf.transpose()\n",
    "                    exportdf[\"Model\"]=model.Model\n",
    "                    exportdf['Mape']=mape.Mape\n",
    "                    exportdf.to_excel(\"forecastsheet.xlsx\")\n",
    "\n",
    "                    return send_file('forecastsheet.xlsx', attachment_filename='forecastsheet.xlsx')\n",
    "                \n",
    "     ##################################################   aggregate by size ##########################################\n",
    "            if inputmethod.strip()=='csv' and aggregator.strip()=='size':\n",
    "                f = request.files['csvfile']\n",
    "                f.save(secure_filename(f.filename))\n",
    "                print(f.filename)\n",
    "                if str(f.filename).endswith('.csv'):\n",
    "                    data=pd.read_csv(\"%s\"%(secure_filename(f.filename)),encoding='latin')\n",
    "                    try:\n",
    "                        data=data[['Group','Month','Total']]\n",
    "                    except:\n",
    "                        return redirect(url_for('index'))\n",
    "                if str(f.filename).endswith('.xlsx') or str(f.filename).endswith('.xls'):\n",
    "                    data=pd.read_excel(\"%s\"%(secure_filename(f.filename)))\n",
    "                    try:\n",
    "                        data=data[['Group','Month','Total']]\n",
    "                    except:\n",
    "                        return redirect(url_for('index'))\n",
    "                    \n",
    "                joined=pd.merge(data, masterdata, left_on='Group',right_on='Cat Cd10 Description', how='left')   \n",
    "                bysize=joined.groupby(['Size Description','Month'])[['Total']].sum()    \n",
    "                bysize.reset_index(inplace=True)\n",
    "                sizes=list(bysize['Size Description'].unique())\n",
    "                    \n",
    "                if model.strip()=='bestfit':\n",
    "                    finaldf=pd.DataFrame()\n",
    "                    mape=pd.DataFrame()\n",
    "                    model=pd.DataFrame()\n",
    "                    columnhead=[]\n",
    "\n",
    "                    for master in sizes:\n",
    "                        count=0\n",
    "                        flag=''\n",
    "                        cleandata,originaldata=iterateclean(bysize,'Size Description',master,startdate,enddate)\n",
    "                        if len(originaldata)>12 and int(max(originaldata.index).strftime(\"%Y\"))==2019:\n",
    "                            try:\n",
    "                                prophet_out,prophet_mape=prophet_forecast(cleandata,originaldata,int(period))\n",
    "                                flag+='a'\n",
    "                            except:\n",
    "                                count+=1\n",
    "                                pass\n",
    "                            try:\n",
    "                                arima_out,arima_mape=arima_forecast(cleandata,originaldata,int(period))\n",
    "                                flag+='b'\n",
    "                            except:\n",
    "                                count+=1\n",
    "                                pass\n",
    "                            try:\n",
    "                                ets_out,ets_mape=ets_forecast(cleandata,originaldata,int(period))\n",
    "                                flag+='c'\n",
    "                            except:\n",
    "                                count+=1\n",
    "                                pass\n",
    "                        else:\n",
    "                            continue\n",
    "                        print(master)\n",
    "                        if count<3:\n",
    "                            if count==2:\n",
    "                                if flag=='a':\n",
    "                                    best=0\n",
    "                                elif flag=='b':\n",
    "                                    best=1\n",
    "                                elif flag=='c':\n",
    "                                    best=2\n",
    "                            elif count==1:\n",
    "                                if flag=='ab':\n",
    "                                    best=min_mape(prophet_mape,arima_mape)\n",
    "                                elif flag=='bc':\n",
    "                                    best=min_mape(arima_mape,ets_mape)+1\n",
    "                                elif flag=='ac':\n",
    "                                    best=min_mape(prophet_mape,ets_mape)\n",
    "                                    if best==1:\n",
    "                                        best+=1\n",
    "                            elif count==0:\n",
    "                                best=min_mape(prophet_mape,arima_mape,ets_mape)\n",
    "                            if best==0:\n",
    "                                model[master]=['Prophet']\n",
    "                                mape[master]=[prophet_mape]\n",
    "                                try:\n",
    "                                    finaldf=pd.concat([finaldf,prophet_out], ignore_index=True, axis=1)\n",
    "                                    columnhead.append(master)\n",
    "                                except:\n",
    "                                    continue\n",
    "                            elif best==1:\n",
    "                                model[master]=['ARIMA']\n",
    "                                mape[master]=[arima_mape]\n",
    "                                try:\n",
    "                                    finaldf=pd.concat([finaldf,arima_out], ignore_index=True, axis=1)\n",
    "                                    columnhead.append(master)\n",
    "                                except:\n",
    "                                    continue\n",
    "                            elif best==2:\n",
    "                                model[master]=['ETS']\n",
    "                                mape[master]=[ets_mape]\n",
    "                                try:\n",
    "                                    finaldf=pd.concat([finaldf,ets_out], ignore_index=True, axis=1)\n",
    "                                    columnhead.append(master)\n",
    "                                except:\n",
    "                                    continue\n",
    "                            else:\n",
    "                                continue\n",
    "                        else:\n",
    "                            continue\n",
    "\n",
    "                    finaldf.columns=columnhead\n",
    "                    mape=mape.transpose()\n",
    "                    model=model.transpose()\n",
    "                    mape.columns=['Mape']\n",
    "                    model.columns=['Model']\n",
    "                    exportdf=finaldf.transpose()\n",
    "                    exportdf[\"Model\"]=model.Model\n",
    "                    exportdf['Mape']=mape.Mape\n",
    "                    exportdf.to_excel(\"forecastsheet.xlsx\")\n",
    "\n",
    "                    return send_file('forecastsheet.xlsx', attachment_filename='forecastsheet.xlsx')\n",
    "\n",
    "                elif model.strip()=='prophet':\n",
    "                    finaldf=pd.DataFrame()\n",
    "                    mape=pd.DataFrame()\n",
    "                    model=pd.DataFrame()\n",
    "                    columnhead=[]\n",
    "\n",
    "                    for master in sizes:\n",
    "                        cleandata,originaldata=iterateclean(bysize,'Size Description',master,startdate,enddate)\n",
    "                        if len(originaldata)>12 and int(max(originaldata.index).strftime(\"%Y\"))==2019:\n",
    "                            try:\n",
    "                                prophet_out,prophet_mape=prophet_forecast(cleandata,originaldata,int(period))\n",
    "                            except:\n",
    "                                pass\n",
    "                        else:\n",
    "                            continue\n",
    "\n",
    "                        try:\n",
    "                            finaldf=pd.concat([finaldf,prophet_out], ignore_index=True, axis=1)\n",
    "                            columnhead.append(master)\n",
    "                        except:\n",
    "                            continue\n",
    "                        model[master]=['Prophet']\n",
    "                        mape[master]=[prophet_mape]\n",
    "\n",
    "                    finaldf.columns=columnhead\n",
    "                    mape=mape.transpose()\n",
    "                    model=model.transpose()\n",
    "                    mape.columns=['Mape']\n",
    "                    model.columns=['Model']\n",
    "                    exportdf=finaldf.transpose()\n",
    "                    exportdf[\"Model\"]=model.Model\n",
    "                    exportdf['Mape']=mape.Mape\n",
    "                    exportdf.to_excel(\"forecastsheet.xlsx\")\n",
    "\n",
    "                    return send_file('forecastsheet.xlsx', attachment_filename='forecastsheet.xlsx')\n",
    "                \n",
    "                elif model.strip()=='arima':\n",
    "                    finaldf=pd.DataFrame()\n",
    "                    mape=pd.DataFrame()\n",
    "                    model=pd.DataFrame()\n",
    "                    columnhead=[]\n",
    "\n",
    "                    for master in sizes:\n",
    "                        cleandata,originaldata=iterateclean(bysize,'Size Description',master,startdate,enddate)\n",
    "                        if len(originaldata)>12 and int(max(originaldata.index).strftime(\"%Y\"))==2019:\n",
    "                            try:\n",
    "                                arima_out,arima_mape=arima_forecast(cleandata,originaldata,int(period))\n",
    "                            except:\n",
    "                                pass\n",
    "                        else:\n",
    "                            continue\n",
    "\n",
    "                        try:\n",
    "                            finaldf=pd.concat([finaldf,arima_out], ignore_index=True, axis=1)\n",
    "                            columnhead.append(master)\n",
    "                        except:\n",
    "                            continue\n",
    "                        model[master]=['ARIMA']\n",
    "                        mape[master]=[arima_mape]\n",
    "\n",
    "                    finaldf.columns=columnhead\n",
    "                    mape=mape.transpose()\n",
    "                    model=model.transpose()\n",
    "                    mape.columns=['Mape']\n",
    "                    model.columns=['Model']\n",
    "                    exportdf=finaldf.transpose()\n",
    "                    exportdf[\"Model\"]=model.Model\n",
    "                    exportdf['Mape']=mape.Mape\n",
    "                    exportdf.to_excel(\"forecastsheet.xlsx\")\n",
    "\n",
    "                    return send_file('forecastsheet.xlsx', attachment_filename='forecastsheet.xlsx')                \n",
    "        \n",
    "        \n",
    "                elif model.strip()=='ets':\n",
    "                    finaldf=pd.DataFrame()\n",
    "                    mape=pd.DataFrame()\n",
    "                    model=pd.DataFrame()\n",
    "                    columnhead=[]\n",
    "\n",
    "                    for master in sizes:\n",
    "                        cleandata,originaldata=iterateclean(bysize,'Size Description',master,startdate,enddate)\n",
    "                        if len(originaldata)>12 and int(max(originaldata.index).strftime(\"%Y\"))==2019:\n",
    "                            try:\n",
    "                                ets_out,ets_mape=ets_forecast(cleandata,originaldata,int(period))\n",
    "                            except:\n",
    "                                pass\n",
    "                        else:\n",
    "                            continue\n",
    "\n",
    "                        try:\n",
    "                            finaldf=pd.concat([finaldf,ets_out], ignore_index=True, axis=1)\n",
    "                            columnhead.append(master)\n",
    "                        except:\n",
    "                            continue\n",
    "                        model[master]=['ETS']\n",
    "                        mape[master]=[ets_mape]\n",
    "\n",
    "                    finaldf.columns=columnhead\n",
    "                    mape=mape.transpose()\n",
    "                    model=model.transpose()\n",
    "                    mape.columns=['Mape']\n",
    "                    model.columns=['Model']\n",
    "                    exportdf=finaldf.transpose()\n",
    "                    exportdf[\"Model\"]=model.Model\n",
    "                    exportdf['Mape']=mape.Mape\n",
    "                    exportdf.to_excel(\"forecastsheet.xlsx\")\n",
    "\n",
    "                    return send_file('forecastsheet.xlsx', attachment_filename='forecastsheet.xlsx')\n",
    "\n",
    "     ##################################################   aggregate by varietal ##########################################\n",
    "            if inputmethod.strip()=='csv' and aggregator.strip()=='varietal':\n",
    "                f = request.files['csvfile']\n",
    "                f.save(secure_filename(f.filename))\n",
    "                print(f.filename)\n",
    "                if str(f.filename).endswith('.csv'):\n",
    "                    data=pd.read_csv(\"%s\"%(secure_filename(f.filename)),encoding='latin')\n",
    "                    try:\n",
    "                        data=data[['Group','Month','Total']]\n",
    "                    except:\n",
    "                        return redirect(url_for('index'))\n",
    "                if str(f.filename).endswith('.xlsx') or str(f.filename).endswith('.xls'):\n",
    "                    data=pd.read_excel(\"%s\"%(secure_filename(f.filename)))\n",
    "                    try:\n",
    "                        data=data[['Group','Month','Total']]\n",
    "                    except:\n",
    "                        return redirect(url_for('index'))\n",
    "                    \n",
    "                joined=pd.merge(data, masterdata, left_on='Group',right_on='Cat Cd10 Description', how='left')   \n",
    "                byvarietal=joined.groupby(['Varietal/ Flavor Description','Month'])[['Total']].sum()    \n",
    "                byvarietal.reset_index(inplace=True)\n",
    "                varietals=list(byvarietal['Varietal/ Flavor Description'].unique())\n",
    "                    \n",
    "                if model.strip()=='bestfit':\n",
    "                    finaldf=pd.DataFrame()\n",
    "                    mape=pd.DataFrame()\n",
    "                    model=pd.DataFrame()\n",
    "                    columnhead=[]\n",
    "\n",
    "                    for master in varietals:\n",
    "                        count=0\n",
    "                        flag=''\n",
    "                        cleandata,originaldata=iterateclean(byvarietal,'Varietal/ Flavor Description',master,startdate,enddate)\n",
    "                        if len(originaldata)>12 and int(max(originaldata.index).strftime(\"%Y\"))==2019:\n",
    "                            try:\n",
    "                                prophet_out,prophet_mape=prophet_forecast(cleandata,originaldata,int(period))\n",
    "                                flag+='a'\n",
    "                            except:\n",
    "                                count+=1\n",
    "                                pass\n",
    "                            try:\n",
    "                                arima_out,arima_mape=arima_forecast(cleandata,originaldata,int(period))\n",
    "                                flag+='b'\n",
    "                            except:\n",
    "                                count+=1\n",
    "                                pass\n",
    "                            try:\n",
    "                                ets_out,ets_mape=ets_forecast(cleandata,originaldata,int(period))\n",
    "                                flag+='c'\n",
    "                            except:\n",
    "                                count+=1\n",
    "                                pass\n",
    "                        else:\n",
    "                            continue\n",
    "                        print(master)\n",
    "                        if count<3:\n",
    "                            if count==2:\n",
    "                                if flag=='a':\n",
    "                                    best=0\n",
    "                                elif flag=='b':\n",
    "                                    best=1\n",
    "                                elif flag=='c':\n",
    "                                    best=2\n",
    "                            elif count==1:\n",
    "                                if flag=='ab':\n",
    "                                    best=min_mape(prophet_mape,arima_mape)\n",
    "                                elif flag=='bc':\n",
    "                                    best=min_mape(arima_mape,ets_mape)+1\n",
    "                                elif flag=='ac':\n",
    "                                    best=min_mape(prophet_mape,ets_mape)\n",
    "                                    if best==1:\n",
    "                                        best+=1\n",
    "                            elif count==0:\n",
    "                                best=min_mape(prophet_mape,arima_mape,ets_mape)\n",
    "                            if best==0:\n",
    "                                model[master]=['Prophet']\n",
    "                                mape[master]=[prophet_mape]\n",
    "                                try:\n",
    "                                    finaldf=pd.concat([finaldf,prophet_out], ignore_index=True, axis=1)\n",
    "                                    columnhead.append(master)\n",
    "                                except:\n",
    "                                    continue\n",
    "                            elif best==1:\n",
    "                                model[master]=['ARIMA']\n",
    "                                mape[master]=[arima_mape]\n",
    "                                try:\n",
    "                                    finaldf=pd.concat([finaldf,arima_out], ignore_index=True, axis=1)\n",
    "                                    columnhead.append(master)\n",
    "                                except:\n",
    "                                    continue\n",
    "                            elif best==2:\n",
    "                                model[master]=['ETS']\n",
    "                                mape[master]=[ets_mape]\n",
    "                                try:\n",
    "                                    finaldf=pd.concat([finaldf,ets_out], ignore_index=True, axis=1)\n",
    "                                    columnhead.append(master)\n",
    "                                except:\n",
    "                                    continue\n",
    "                            else:\n",
    "                                continue\n",
    "                        else:\n",
    "                            continue\n",
    "\n",
    "                    finaldf.columns=columnhead\n",
    "                    mape=mape.transpose()\n",
    "                    model=model.transpose()\n",
    "                    mape.columns=['Mape']\n",
    "                    model.columns=['Model']\n",
    "                    exportdf=finaldf.transpose()\n",
    "                    exportdf[\"Model\"]=model.Model\n",
    "                    exportdf['Mape']=mape.Mape\n",
    "                    exportdf.to_excel(\"forecastsheet.xlsx\")\n",
    "\n",
    "                    return send_file('forecastsheet.xlsx', attachment_filename='forecastsheet.xlsx')\n",
    "\n",
    "                elif model.strip()=='prophet':\n",
    "                    finaldf=pd.DataFrame()\n",
    "                    mape=pd.DataFrame()\n",
    "                    model=pd.DataFrame()\n",
    "                    columnhead=[]\n",
    "\n",
    "                    for master in varietals:\n",
    "                        cleandata,originaldata=iterateclean(byvarietal,'Varietal/ Flavor Description',master,startdate,enddate)\n",
    "                        if len(originaldata)>12 and int(max(originaldata.index).strftime(\"%Y\"))==2019:\n",
    "                            try:\n",
    "                                prophet_out,prophet_mape=prophet_forecast(cleandata,originaldata,int(period))\n",
    "                            except:\n",
    "                                pass\n",
    "                        else:\n",
    "                            continue\n",
    "\n",
    "                        try:\n",
    "                            finaldf=pd.concat([finaldf,prophet_out], ignore_index=True, axis=1)\n",
    "                            columnhead.append(master)\n",
    "                        except:\n",
    "                            continue\n",
    "                        model[master]=['Prophet']\n",
    "                        mape[master]=[prophet_mape]\n",
    "\n",
    "                    finaldf.columns=columnhead\n",
    "                    mape=mape.transpose()\n",
    "                    model=model.transpose()\n",
    "                    mape.columns=['Mape']\n",
    "                    model.columns=['Model']\n",
    "                    exportdf=finaldf.transpose()\n",
    "                    exportdf[\"Model\"]=model.Model\n",
    "                    exportdf['Mape']=mape.Mape\n",
    "                    exportdf.to_excel(\"forecastsheet.xlsx\")\n",
    "\n",
    "                    return send_file('forecastsheet.xlsx', attachment_filename='forecastsheet.xlsx')\n",
    "                \n",
    "                elif model.strip()=='arima':\n",
    "                    finaldf=pd.DataFrame()\n",
    "                    mape=pd.DataFrame()\n",
    "                    model=pd.DataFrame()\n",
    "                    columnhead=[]\n",
    "\n",
    "                    for master in varietals:\n",
    "                        cleandata,originaldata=iterateclean(byvarietal,'Varietal/ Flavor Description',master,startdate,enddate)\n",
    "                        if len(originaldata)>12 and int(max(originaldata.index).strftime(\"%Y\"))==2019:\n",
    "                            try:\n",
    "                                arima_out,arima_mape=arima_forecast(cleandata,originaldata,int(period))\n",
    "                            except:\n",
    "                                pass\n",
    "                        else:\n",
    "                            continue\n",
    "\n",
    "                        try:\n",
    "                            finaldf=pd.concat([finaldf,arima_out], ignore_index=True, axis=1)\n",
    "                            columnhead.append(master)\n",
    "                        except:\n",
    "                            continue\n",
    "                        model[master]=['ARIMA']\n",
    "                        mape[master]=[arima_mape]\n",
    "\n",
    "                    finaldf.columns=columnhead\n",
    "                    mape=mape.transpose()\n",
    "                    model=model.transpose()\n",
    "                    mape.columns=['Mape']\n",
    "                    model.columns=['Model']\n",
    "                    exportdf=finaldf.transpose()\n",
    "                    exportdf[\"Model\"]=model.Model\n",
    "                    exportdf['Mape']=mape.Mape\n",
    "                    exportdf.to_excel(\"forecastsheet.xlsx\")\n",
    "\n",
    "                    return send_file('forecastsheet.xlsx', attachment_filename='forecastsheet.xlsx')                \n",
    "        \n",
    "        \n",
    "                elif model.strip()=='ets':\n",
    "                    finaldf=pd.DataFrame()\n",
    "                    mape=pd.DataFrame()\n",
    "                    model=pd.DataFrame()\n",
    "                    columnhead=[]\n",
    "\n",
    "                    for master in varietals:\n",
    "                        cleandata,originaldata=iterateclean(byvarietal,'Varietal/ Flavor Description',master,startdate,enddate)\n",
    "                        if len(originaldata)>12 and int(max(originaldata.index).strftime(\"%Y\"))==2019:\n",
    "                            try:\n",
    "                                ets_out,ets_mape=ets_forecast(cleandata,originaldata,int(period))\n",
    "                            except:\n",
    "                                pass\n",
    "                        else:\n",
    "                            continue\n",
    "\n",
    "                        try:\n",
    "                            finaldf=pd.concat([finaldf,ets_out], ignore_index=True, axis=1)\n",
    "                            columnhead.append(master)\n",
    "                        except:\n",
    "                            continue\n",
    "                        model[master]=['ETS']\n",
    "                        mape[master]=[ets_mape]\n",
    "\n",
    "                    finaldf.columns=columnhead\n",
    "                    mape=mape.transpose()\n",
    "                    model=model.transpose()\n",
    "                    mape.columns=['Mape']\n",
    "                    model.columns=['Model']\n",
    "                    exportdf=finaldf.transpose()\n",
    "                    exportdf[\"Model\"]=model.Model\n",
    "                    exportdf['Mape']=mape.Mape\n",
    "                    exportdf.to_excel(\"forecastsheet.xlsx\")\n",
    "\n",
    "                    return send_file('forecastsheet.xlsx', attachment_filename='forecastsheet.xlsx')\n",
    "\n",
    "                \n",
    "     ##################################################   aggregate by brand+size ##########################################\n",
    "            if inputmethod.strip()=='csv' and aggregator.strip()=='varietal':\n",
    "                f = request.files['csvfile']\n",
    "                f.save(secure_filename(f.filename))\n",
    "                print(f.filename)\n",
    "                if str(f.filename).endswith('.csv'):\n",
    "                    data=pd.read_csv(\"%s\"%(secure_filename(f.filename)),encoding='latin')\n",
    "                    try:\n",
    "                        data=data[['Group','Month','Total']]\n",
    "                    except:\n",
    "                        return redirect(url_for('index'))\n",
    "                if str(f.filename).endswith('.xlsx') or str(f.filename).endswith('.xls'):\n",
    "                    data=pd.read_excel(\"%s\"%(secure_filename(f.filename)))\n",
    "                    try:\n",
    "                        data=data[['Group','Month','Total']]\n",
    "                    except:\n",
    "                        return redirect(url_for('index'))\n",
    "                    \n",
    "                joined=pd.merge(data, masterdata, left_on='Group',right_on='Cat Cd10 Description', how='left')   \n",
    "                bybrandsize=joined.groupby(['Brand Description','Size Description','Month'])[['Total']].sum()     \n",
    "                bybrandsize.reset_index(inplace=True)\n",
    "                bybrandsize['Brand Description']=bybrandsize['Brand Description']+' -'+bybrandsize['Size Description']\n",
    "                bybrandsize=bybrandsize.drop(['Size Description'],axis=1)\n",
    "                brandsizes=list(bybrandsize['Brand Description'].unique())\n",
    "                    \n",
    "                if model.strip()=='bestfit':\n",
    "                    finaldf=pd.DataFrame()\n",
    "                    mape=pd.DataFrame()\n",
    "                    model=pd.DataFrame()\n",
    "                    columnhead=[]\n",
    "\n",
    "                    for master in brandsizes:\n",
    "                        count=0\n",
    "                        flag=''\n",
    "                        cleandata,originaldata=iterateclean(bybrandsize,'Brand Description',master,startdate,enddate)\n",
    "                        if len(originaldata)>12 and int(max(originaldata.index).strftime(\"%Y\"))==2019:\n",
    "                            try:\n",
    "                                prophet_out,prophet_mape=prophet_forecast(cleandata,originaldata,int(period))\n",
    "                                flag+='a'\n",
    "                            except:\n",
    "                                count+=1\n",
    "                                pass\n",
    "                            try:\n",
    "                                arima_out,arima_mape=arima_forecast(cleandata,originaldata,int(period))\n",
    "                                flag+='b'\n",
    "                            except:\n",
    "                                count+=1\n",
    "                                pass\n",
    "                            try:\n",
    "                                ets_out,ets_mape=ets_forecast(cleandata,originaldata,int(period))\n",
    "                                flag+='c'\n",
    "                            except:\n",
    "                                count+=1\n",
    "                                pass\n",
    "                        else:\n",
    "                            continue\n",
    "                        print(master)\n",
    "                        if count<3:\n",
    "                            if count==2:\n",
    "                                if flag=='a':\n",
    "                                    best=0\n",
    "                                elif flag=='b':\n",
    "                                    best=1\n",
    "                                elif flag=='c':\n",
    "                                    best=2\n",
    "                            elif count==1:\n",
    "                                if flag=='ab':\n",
    "                                    best=min_mape(prophet_mape,arima_mape)\n",
    "                                elif flag=='bc':\n",
    "                                    best=min_mape(arima_mape,ets_mape)+1\n",
    "                                elif flag=='ac':\n",
    "                                    best=min_mape(prophet_mape,ets_mape)\n",
    "                                    if best==1:\n",
    "                                        best+=1\n",
    "                            elif count==0:\n",
    "                                best=min_mape(prophet_mape,arima_mape,ets_mape)\n",
    "                            if best==0:\n",
    "                                model[master]=['Prophet']\n",
    "                                mape[master]=[prophet_mape]\n",
    "                                try:\n",
    "                                    finaldf=pd.concat([finaldf,prophet_out], ignore_index=True, axis=1)\n",
    "                                    columnhead.append(master)\n",
    "                                except:\n",
    "                                    continue\n",
    "                            elif best==1:\n",
    "                                model[master]=['ARIMA']\n",
    "                                mape[master]=[arima_mape]\n",
    "                                try:\n",
    "                                    finaldf=pd.concat([finaldf,arima_out], ignore_index=True, axis=1)\n",
    "                                    columnhead.append(master)\n",
    "                                except:\n",
    "                                    continue\n",
    "                            elif best==2:\n",
    "                                model[master]=['ETS']\n",
    "                                mape[master]=[ets_mape]\n",
    "                                try:\n",
    "                                    finaldf=pd.concat([finaldf,ets_out], ignore_index=True, axis=1)\n",
    "                                    columnhead.append(master)\n",
    "                                except:\n",
    "                                    continue\n",
    "                            else:\n",
    "                                continue\n",
    "                        else:\n",
    "                            continue\n",
    "\n",
    "                    finaldf.columns=columnhead\n",
    "                    mape=mape.transpose()\n",
    "                    model=model.transpose()\n",
    "                    mape.columns=['Mape']\n",
    "                    model.columns=['Model']\n",
    "                    exportdf=finaldf.transpose()\n",
    "                    exportdf[\"Model\"]=model.Model\n",
    "                    exportdf['Mape']=mape.Mape\n",
    "                    exportdf.to_excel(\"forecastsheet.xlsx\")\n",
    "\n",
    "                    return send_file('forecastsheet.xlsx', attachment_filename='forecastsheet.xlsx')\n",
    "\n",
    "                elif model.strip()=='prophet':\n",
    "                    finaldf=pd.DataFrame()\n",
    "                    mape=pd.DataFrame()\n",
    "                    model=pd.DataFrame()\n",
    "                    columnhead=[]\n",
    "\n",
    "                    for master in brandsizes:\n",
    "                        cleandata,originaldata=iterateclean(bybrandsize,'Brand Description',master,startdate,enddate)\n",
    "                        if len(originaldata)>12 and int(max(originaldata.index).strftime(\"%Y\"))==2019:\n",
    "                            try:\n",
    "                                prophet_out,prophet_mape=prophet_forecast(cleandata,originaldata,int(period))\n",
    "                            except:\n",
    "                                pass\n",
    "                        else:\n",
    "                            continue\n",
    "\n",
    "                        try:\n",
    "                            finaldf=pd.concat([finaldf,prophet_out], ignore_index=True, axis=1)\n",
    "                            columnhead.append(master)\n",
    "                        except:\n",
    "                            continue\n",
    "                        model[master]=['Prophet']\n",
    "                        mape[master]=[prophet_mape]\n",
    "\n",
    "                    finaldf.columns=columnhead\n",
    "                    mape=mape.transpose()\n",
    "                    model=model.transpose()\n",
    "                    mape.columns=['Mape']\n",
    "                    model.columns=['Model']\n",
    "                    exportdf=finaldf.transpose()\n",
    "                    exportdf[\"Model\"]=model.Model\n",
    "                    exportdf['Mape']=mape.Mape\n",
    "                    exportdf.to_excel(\"forecastsheet.xlsx\")\n",
    "\n",
    "                    return send_file('forecastsheet.xlsx', attachment_filename='forecastsheet.xlsx')\n",
    "                \n",
    "                elif model.strip()=='arima':\n",
    "                    finaldf=pd.DataFrame()\n",
    "                    mape=pd.DataFrame()\n",
    "                    model=pd.DataFrame()\n",
    "                    columnhead=[]\n",
    "\n",
    "                    for master in brandsizes:\n",
    "                        cleandata,originaldata=iterateclean(bybrandsize,'Brand Description',master,startdate,enddate)\n",
    "                        if len(originaldata)>12 and int(max(originaldata.index).strftime(\"%Y\"))==2019:\n",
    "                            try:\n",
    "                                arima_out,arima_mape=arima_forecast(cleandata,originaldata,int(period))\n",
    "                            except:\n",
    "                                pass\n",
    "                        else:\n",
    "                            continue\n",
    "\n",
    "                        try:\n",
    "                            finaldf=pd.concat([finaldf,arima_out], ignore_index=True, axis=1)\n",
    "                            columnhead.append(master)\n",
    "                        except:\n",
    "                            continue\n",
    "                        model[master]=['ARIMA']\n",
    "                        mape[master]=[arima_mape]\n",
    "\n",
    "                    finaldf.columns=columnhead\n",
    "                    mape=mape.transpose()\n",
    "                    model=model.transpose()\n",
    "                    mape.columns=['Mape']\n",
    "                    model.columns=['Model']\n",
    "                    exportdf=finaldf.transpose()\n",
    "                    exportdf[\"Model\"]=model.Model\n",
    "                    exportdf['Mape']=mape.Mape\n",
    "                    exportdf.to_excel(\"forecastsheet.xlsx\")\n",
    "\n",
    "                    return send_file('forecastsheet.xlsx', attachment_filename='forecastsheet.xlsx')                \n",
    "        \n",
    "        \n",
    "                elif model.strip()=='ets':\n",
    "                    finaldf=pd.DataFrame()\n",
    "                    mape=pd.DataFrame()\n",
    "                    model=pd.DataFrame()\n",
    "                    columnhead=[]\n",
    "\n",
    "                    for master in brandsizes:\n",
    "                        cleandata,originaldata=iterateclean(bybrandsize,'Brand Description',master,startdate,enddate)\n",
    "                        if len(originaldata)>12 and int(max(originaldata.index).strftime(\"%Y\"))==2019:\n",
    "                            try:\n",
    "                                ets_out,ets_mape=ets_forecast(cleandata,originaldata,int(period))\n",
    "                            except:\n",
    "                                pass\n",
    "                        else:\n",
    "                            continue\n",
    "\n",
    "                        try:\n",
    "                            finaldf=pd.concat([finaldf,ets_out], ignore_index=True, axis=1)\n",
    "                            columnhead.append(master)\n",
    "                        except:\n",
    "                            continue\n",
    "                        model[master]=['ETS']\n",
    "                        mape[master]=[ets_mape]\n",
    "\n",
    "                    finaldf.columns=columnhead\n",
    "                    mape=mape.transpose()\n",
    "                    model=model.transpose()\n",
    "                    mape.columns=['Mape']\n",
    "                    model.columns=['Model']\n",
    "                    exportdf=finaldf.transpose()\n",
    "                    exportdf[\"Model\"]=model.Model\n",
    "                    exportdf['Mape']=mape.Mape\n",
    "                    exportdf.to_excel(\"forecastsheet.xlsx\")\n",
    "\n",
    "                    return send_file('forecastsheet.xlsx', attachment_filename='forecastsheet.xlsx')\n",
    "                \n",
    "                \n",
    "                \n",
    "        elif request.form['action'] == 'View':\n",
    "            brand=request.form.getlist('brand')\n",
    "            size=request.form.getlist('size')\n",
    "            varietal=request.form.getlist('varietal')\n",
    "            mastercodelist=request.form.getlist('mastercode')\n",
    "            print(brand)\n",
    "            print(size)\n",
    "            print(varietal)\n",
    "            print(mastercodelist)\n",
    "            if len(mastercodelist)<1:\n",
    "                selecteddata=masterdata[masterdata['Brand Description'].isin(brand) & masterdata['Size Description'].isin(size) & masterdata['Varietal/ Flavor Description'].isin(varietal)]\n",
    "                codes=list(selecteddata['Cat Cd10 Description'].unique())\n",
    "                data=pd.read_excel(r\"privatedata\\forecastsheet.xlsx\")\n",
    "                graphdata=data[data.iloc[:,0].isin(codes)]\n",
    "                graphvalues=graphdata.iloc[:,1:-2].sum()\n",
    "                labels=list(pd.to_datetime(graphvalues.index).map(lambda x: x.strftime(\"%b %y\")))\n",
    "                values=list(graphvalues.values)\n",
    "                legend=\"Monthly Shipments\"\n",
    "                return render_template('index.html',values=values,labels=labels,legend=legend)\n",
    "            else:\n",
    "                data=pd.read_excel(r\"privatedata\\forecastsheet.xlsx\")\n",
    "                graphdata=data[data.iloc[:,0].isin(mastercodelist)]\n",
    "                graphvalues=graphdata.iloc[:,1:-2].sum()\n",
    "                labels=list(pd.to_datetime(graphvalues.index).map(lambda x: x.strftime(\"%b %y\")))\n",
    "                values=list(graphvalues.values)\n",
    "                legend=\"Monthly Shipments\"\n",
    "                return render_template('index.html',values=values,labels=labels,legend=legend)\n",
    "                \n",
    "                \n",
    "\n",
    "            \n",
    "if __name__ == '__main__':\n",
    "    app.run(port=9000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
